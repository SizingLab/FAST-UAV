{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAST-UAV - Uncertainty analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to run uncertainty analyses in order to evaluate the impacts of models uncertainty and input parameters uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first place, we define in the configuration file the UAV models that will be used to run the analyses. Here, no optimization of the design is carried out, i.e. we start from an existing design and analyse its performance on a given mission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\envs\\OAD\\lib\\site-packages\\pyoptsparse\\pyOpt_MPI.py:68: UserWarning: mpi4py could not be imported. mpi4py is required to use the parallel gradient analysis and parallel objective analysis for non-gradient based optimizers. Continuing using a dummy MPI module from pyOptSparse.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os.path as pth\n",
    "import openmdao.api as om\n",
    "import logging\n",
    "import shutil\n",
    "import fastoad.api as oad\n",
    "from time import time\n",
    "from openmdao_drivers.cmaes_driver import CMAESDriver\n",
    "from nrel_openmdao_extensions.nlopt_driver import NLoptDriver\n",
    "import cma\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.postprocessing.sensitivity_analysis.sensitivity_analysis import (\n",
    "    morris_analysis,\n",
    "    sobol_analysis,\n",
    ")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 16, 8\n",
    "plt.rcParams.update({\"font.size\": 13})\n",
    "\n",
    "DATA_FOLDER_PATH = \"data\"\n",
    "WORK_FOLDER_PATH = \"workdir\"\n",
    "\n",
    "# For having log messages display on screen\n",
    "# logging.basicConfig(level=logging.INFO, format='%(levelname)-8s: %(message)s')\n",
    "\n",
    "# For using all screen width\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining two problems that will be useful for the uncertainty analysis:\n",
    "\n",
    "- The first problem consists of the UAV model alone. In this problem, no optimization of any kind is carried out and the model is run once.\n",
    "- The second problem is made of the UAV model on which a consistency optimization in run. That is, the system consistency is guaranteed even if the inputs parameters of the problem are modified. For more information about the consistency constraints please refer to Delbecq et al. article available [here](https://oatao.univ-toulouse.fr/26691/).\n",
    "\n",
    "These problems are deterministic, i.e. they take as inputs fixed values and return deterministic outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CONF_FILE = pth.join(DATA_FOLDER_PATH, \"multirotor_model.yaml\")  # Problem without consistency constraint solving\n",
    "CONF_FILE_CONSISTENT = pth.join(DATA_FOLDER_PATH, \"multirotor_model_consistency.yaml\")  # Problem with consistency constraints solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"workdir\\n2.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x19fc147a5e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N2_FILE = pth.join(WORK_FOLDER_PATH, \"n2.html\")\n",
    "oad.write_n2(CONF_FILE, N2_FILE, overwrite=True)\n",
    "from IPython.display import IFrame\n",
    "IFrame(src=N2_FILE, width=\"100%\", height=\"500px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load an existing UAV design on which the uncertainty analysis will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb41ad266204e2394d8f855e7cbb63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Load', icon='upload', style=ButtonStyle(), tooltip='Load the…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SOURCE_FILE = pth.join(DATA_FOLDER_PATH, \"problem_outputs_DJI_M600_mdo.xml\")\n",
    "oad.variable_viewer(SOURCE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the source file is consistent with the problem definition and the models, a simple run is carried out. No difference between the values of the source file and the output values of the problem should be observed.<br>\n",
    "We will continue this notebook with the output values of the deterministic problem. These deterministic values are stored in a separate XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 1.5328299458777948\n",
      "            Iterations: 1\n",
      "            Function evaluations: 1\n",
      "            Gradient evaluations: 1\n",
      "Optimization Complete\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce90b0e69b764a398f14594671091911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Load', icon='upload', style=ButtonStyle(), tooltip='Load the…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INPUT_FILE = oad.generate_inputs(CONF_FILE, SOURCE_FILE, overwrite=True)\n",
    "# problem = oad.optimize_problem(CONF_FILE, overwrite=True)  # Run model once (no optimization)\n",
    "problem = oad.optimize_problem(CONF_FILE_CONSISTENT, overwrite=True)  # Run model with consistency constraints\n",
    "DETERMINISTIC_FILE = pth.join(WORK_FOLDER_PATH, \"model_outputs.xml\")\n",
    "oad.variable_viewer(DETERMINISTIC_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Design of Experiments\n",
    "\n",
    "In contrast with a single problem evaluation, the uncertainty analysis relies on multiple evaluations of the problem to analyse the effects of varying one or several parameters on the output variables of interest.\n",
    "\n",
    "The [OpenTurns](https://openturns.github.io/openturns/latest/index.html) and [SALib](https://salib.readthedocs.io/en/latest/index.html) libraries are used to set up the DoEs and run the sensitivity analyses. \n",
    "The drivers to connect these librairies to FAST-UAV are provided by Onera's [OpenMDAO Extensions](https://github.com/OneraHub/openmdao_extensions).\n",
    "\n",
    "Keep in mind that two distinct approaches for the uncertainty analysis are possible:\n",
    "- in the first approach (*'CONF_FILE'*), a single straightforward calculation of the models is carried out;\n",
    "- in the approach (*'CONF_FILE_CONSISTENT'*), the driver will iterate over the consistency variables to ensure system consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Screening procedure - Morris method\n",
    "\n",
    "The Morris method allows to get a measure of importance and interaction of input factors. It is used as a screening method to reduce the number of parameters prior to a more detailed analysis.\n",
    "\n",
    "The `morris_analysis` function takes the following inputs:\n",
    "- The configuration file of the problem to be evaluated;\n",
    "- The source file containing the deterministic design, to help the user to set up the analysis (uncertain parameters selection, output variable of interest, ...). \n",
    "\n",
    "The number of simulation runs required are $r(k+1)$ where $r$ is the number of trajectories (typically between 4 to 10) and $k$ the number of parameters.\n",
    "\n",
    "**Bibliography**\n",
    "\n",
    "> Ruano, M.V., Ribes, J., Seco, A., Ferrer, J., 2012. An improved sampling strategy based on trajectory design for application of the Morris method to systems with many input factors. Environmental Modelling & Software 37, 103–109. https://doi.org/10.1016/j.envsoft.2012.03.008\n",
    "\n",
    "> Morris, M.D., 1991. Factorial Sampling Plans for Preliminary Computational Experiments. Technometrics 33, 161–174. https://doi.org/10.1080/00401706.1991.10484804\n",
    "\n",
    "> Campolongo, F., Cariboni, J., Saltelli, A., 2007. An effective screening design for sensitivity analysis of large models. Environmental Modelling & Software, Modelling, computer-assisted simulations, and mapping of dangerous phenomena for hazard assessment 22, 1509–1518. https://doi.org/10.1016/j.envsoft.2006.10.004\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2da092dacb4472abec82a43a6eecfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FigureWidget({\n",
       "    'data': [{'error_y': {'array': [], 'type': 'data'},\n",
       "         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# morris_analysis(CONF_FILE, DETERMINISTIC_FILE)\n",
    "morris_analysis(CONF_FILE_CONSISTENT, DETERMINISTIC_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Global sensitivity analysis - Sobol' indices using Saltelli's sampling scheme\n",
    "\n",
    "The Sobol' method allows to get a representation of the contribution of the inputs to the overall uncertainty in the model output. The space of the uncertain inputs is explored with a Monte Carlo sampling (here Saltelli's scheme, which extends the Sobol' sequence in a way to reduce the error rates in the resulting sensitivity index calculations).\n",
    "\n",
    "The number of simulation runs required are $m(k+2)$ where $m$ is the number of samples (typically between 100s to 1000s) and $k$ the number of parameters.\n",
    "\n",
    "**Bibliography**\n",
    "\n",
    "> Campolongo, F., Saltelli, A., Cariboni, J., 2011. From screening to quantitative sensitivity analysis. A unified approach. Computer Physics Communications 182, 978–988. https://doi.org/10.1016/j.cpc.2010.12.039\n",
    "\n",
    "> Saltelli, A., 2002. Making best use of model evaluations to compute sensitivity indices. Computer Physics Communications 145, 280–297. https://doi.org/10.1016/S0010-4655(02)00280-1\n",
    "\n",
    "> Sobol’, I.M., 2001. Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates. Mathematics and Computers in Simulation, The Second IMACS Seminar on Monte Carlo Methods 55, 271–280. https://doi.org/10.1016/S0378-4754(00)00270-6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bc0d7be32144428def0f3cf48eefe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FigureWidget({\n",
       "    'data': [{'error_y': {'array': [], 'type': 'data'},\n",
       "         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sobol_analysis(CONF_FILE, DETERMINISTIC_FILE)\n",
    "sobol_analysis(CONF_FILE_CONSISTENT, DETERMINISTIC_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 -  Expert mode\n",
    "You may reuse data from the DoEs ran with `morris_analysis` and `sobol_analysis` methods to display custom plots or run new analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from utils.postprocessing.sensitivity_analysis.sobol_plot import sobol_plot\n",
    "from utils.postprocessing.sensitivity_analysis.morris_plot import morris_plot\n",
    "from SALib.analyze import sobol, morris\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 20, \"lines.markersize\": 10})\n",
    "SA_PATH = \"./workdir/sensitivity_analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MORRIS METHOD\n",
    "\n",
    "# Load DoE csv file\n",
    "df_morris = pd.read_csv(SA_PATH + \"/doe_Morris.csv\", sep=\",\")\n",
    "\n",
    "# Load problem and output definitions\n",
    "f_problem = open(SA_PATH + \"/problem_morris.txt\", \"r\")\n",
    "f_inputs = open(SA_PATH + \"/x_morris.txt\", \"r\")\n",
    "f_output = open(SA_PATH + \"/y_morris.txt\", \"r\")\n",
    "# print(f_problem.read())\n",
    "problem = eval(f_problem.read())\n",
    "x = eval(f_inputs.read())\n",
    "y = f_output.read()\n",
    "f_problem.close()\n",
    "f_inputs.close()\n",
    "f_output.close()\n",
    "\n",
    "# Read data\n",
    "X = df_morris[x].to_numpy()\n",
    "Y = df_morris[y].to_numpy()\n",
    "\n",
    "# Run Morris analysis with SALib\n",
    "Si = morris.analyze(\n",
    "    problem, X, Y, print_to_console=False, conf_level=0.95, num_resamples=100\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "fig = morris_plot(Si, unit=\"(min)\")\n",
    "plt.savefig(SA_PATH + \"/figures/morris_plot.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOBOL' METHOD\n",
    "\n",
    "# Load DoE csv file\n",
    "df_sobol = pd.read_csv(SA_PATH + \"/doe_Sobol.csv\", sep=\",\")\n",
    "\n",
    "# Load problem and output definitions\n",
    "f_problem = open(SA_PATH + \"/problem_sobol.txt\", \"r\")\n",
    "f_output = open(SA_PATH + \"/y_sobol.txt\", \"r\")\n",
    "problem = eval(f_problem.read())\n",
    "y = f_output.read()\n",
    "f_problem.close()\n",
    "f_output.close()\n",
    "\n",
    "# Read data\n",
    "Y = df_sobol[y].to_numpy()\n",
    "\n",
    "# Run Sobol analysis with SALib\n",
    "Si = sobol.analyze(problem, Y, calc_second_order=True)\n",
    "\n",
    "# Plot results\n",
    "fig = sobol_plot(Si)\n",
    "plt.savefig(SA_PATH + \"/figures/sobol_plot.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT DISTRIBUTION\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "df_output = pd.read_csv(SA_PATH + \"/doe_Sobol.csv\", sep=\",\")\n",
    "mu, std = norm.fit(df_output[y])\n",
    "print(\"mu = \", mu)\n",
    "print(\"std = \", std)\n",
    "\n",
    "# Plot the histogram.\n",
    "q25, q75 = np.percentile(df_output[y], [25, 75])\n",
    "bin_width = (\n",
    "    2 * (q75 - q25) * len(df_output[y]) ** (-1 / 3)\n",
    ")  # Freedman–Diaconis number of bins\n",
    "bins = round((df_output[y].max() - df_output[y].min()) / bin_width)\n",
    "plt.hist(\n",
    "    df_output[y],\n",
    "    bins=bins,\n",
    "    density=True,\n",
    "    alpha=1.0,\n",
    "    rwidth=0.85,\n",
    "    label=\"output distribution\",\n",
    ")\n",
    "\n",
    "# Plot the PDF.\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, \"r\", linewidth=5, label=\"normal distribution\")\n",
    "\n",
    "plt.xlabel(\"Hover Autonomy (min)\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "\n",
    "# fig = sns.displot(df_sobol, x=y, kde=True, stat=\"probability\", binwidth=0.5, aspect=1.5)\n",
    "# fig.set_axis_labels(\"Hover autonomy (min)\", \"Probability\")\n",
    "\n",
    "plt.savefig(SA_PATH + \"/figures/output_dist.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
