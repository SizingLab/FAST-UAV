{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAST-UAV - Life Cycle Assessments of multirotor UAVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FAST-OAD](https://fast-oad.readthedocs.io) is a framework for performing rapid Overall Aircraft Design. The computational core of FAST-OAD is based on the  [OpenMDAO framework](https://openmdao.org/). <br>\n",
    "FAST-UAV is the drone declination of FAST-OAD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up and analyzing the initial problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To organize our work, we propose to use two user folders `data/` and `workdir/`. For instance, in `data/` we store a XML file which describes the [DJI Matrice 600 Pro](https://www.dji.com/matrice600-pro) multicopter. In `workdir/`, we store files generated or modified by FAST-UAV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as pth\n",
    "import openmdao.api as om\n",
    "import logging\n",
    "import shutil\n",
    "import fastoad.api as oad\n",
    "from fastuav.cmd.lca import *\n",
    "from time import time\n",
    "from IPython.display import IFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import brightway2 as bw\n",
    "from fastuav.utils.postprocessing.analysis_and_plots import *\n",
    "from fastuav.utils.postprocessing.lca import *\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 16, 8\n",
    "plt.rcParams.update({\"font.size\": 13})\n",
    "\n",
    "# Declare paths to folders and files\n",
    "DATA_FOLDER_PATH = \"./data\"\n",
    "WORK_FOLDER_PATH = \"./workdir\"\n",
    "CONFIGURATION_FOLDER_PATH = pth.join(DATA_FOLDER_PATH, \"configurations\")\n",
    "SOURCE_FOLDER_PATH = pth.join(DATA_FOLDER_PATH, \"source_files\")\n",
    "\n",
    "CONFIGURATION_FILE = pth.join(CONFIGURATION_FOLDER_PATH, \"multirotor_mdo_lca.yaml\") # You may provide a different configuration file\n",
    "SOURCE_FILE = pth.join(SOURCE_FOLDER_PATH, \"problem_inputs_lca.xml\") # You may provide a different source file\n",
    "\n",
    "CONFIGURATION_FILE_LCA_ONLY = pth.join(CONFIGURATION_FOLDER_PATH, \"multirotor_lca.yaml\")\n",
    "\n",
    "# For having log messages display on screen\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)-8s: %(message)s\")\n",
    "\n",
    "# For using all screen width\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "The YAML configuration file located in the data folder defines the design problem, i.e. the model, the problem driver and the optimization problem definition.<br>\n",
    "A useful feature is the [N2 diagram](http://openmdao.org/twodocs/versions/latest/basic_guide/make_n2.html) visualization available in OpenMDAO to see the structure of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N2_FILE = pth.join(WORK_FOLDER_PATH, \"n2.html\")\n",
    "oad.write_n2(CONFIGURATION_FILE, N2_FILE, overwrite=True)\n",
    "IFrame(src=N2_FILE, width=\"100%\", height=\"500px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#oad.generate_configuration_file(\n",
    "#    CONFIGURATION_FILE_LCA_ONLY, overwrite=True, distribution_name=\"fastuav\", sample_file_name=\"multirotor_lca.yaml\"\n",
    "#)\n",
    "LCA_FILE = pth.join(WORK_FOLDER_PATH, \"LCA_processes.html\")\n",
    "net = graph_activities(CONFIGURATION_FILE)\n",
    "net.show(LCA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the configuration file, we have specified an input file name 'problem_inputs.xml'. We can ask FAST-UAV to generate the inputs of the model with the reference parameters from 'problem_inputs_DJI_M600.xml' as default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oad.generate_inputs(CONFIGURATION_FILE, SOURCE_FILE, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now checkout the generated [input file](./workdir/problem_inputs.xml). The values in this file can be modified by the user and will be considered by FAST-UAV when executing a computational process.<br>\n",
    "The `variable-viewer` provides a way to inspect and modify the content of the XML file. The dropdown lists above the table allow to filter the displayed variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = pth.join(WORK_FOLDER_PATH, \"problem_inputs.xml\")\n",
    "oad.variable_viewer(INPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running an MDO\n",
    "\n",
    "You can now run an optimization problem. The last part of the configuration file .yaml is where this optimization problem is defined:\n",
    "\n",
    "```yaml\n",
    "optimization:\n",
    "  design_variables:\n",
    "    - name: data:weights:mtow:k # over estimation coefficient on the load mass\n",
    "      upper: 40.0\n",
    "      lower: 1.0\n",
    "  constraints:\n",
    "    - name: data:weights:mtow:guess:constraint # mass consistency\n",
    "      lower: 0.0\n",
    "  objective:\n",
    "    - name: data:weights:mtow\n",
    "      scaler: 1e-1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_problem = oad.evaluate_problem(CONFIGURATION_FILE, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optim_problem = oad.optimize_problem(CONFIGURATION_FILE, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import lca_algebraic as agb\n",
    "#from lcav.io.configuration import LCAProblemConfigurator\n",
    "#import sympy as sym\n",
    "\n",
    "#_, model, methods = LCAProblemConfigurator('./data/lca/lca_model.yaml').generate()\n",
    "\n",
    "#agb.lca.compute_impacts(model, methods, axis='phase')\n",
    "#parameters = agb.all_params().values()\n",
    "\n",
    "#lambdas = agb.lca._preMultiLCAAlgebric(model, methods)\n",
    "\n",
    "# Compile expressions for partial derivatives of impacts\n",
    "#partial_lambdas_dict = {method: [lambd.expr.diff(param)]}\n",
    "#partial_lambdas_dict = {param.name: [agb.lca.LambdaWithParamNames(lambd.expr.replace(sym.ceiling, lambda x: x).diff(param)) for lambd in lambdas] for param in parameters} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save these results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_FILE = pth.join(WORK_FOLDER_PATH, \"problem_outputs.xml\")\n",
    "MDO_OUTPUT_FILE = pth.join(DATA_FOLDER_PATH, 'problem_outputs_lca_mdo.xml')\n",
    "shutil.copy(OUTPUT_FILE, MDO_OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `optimizer_viewer` offers a convenient summary of the optimization result. If design variables or constraints have active bounds they are yellow whereas they are red if they are violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oad.optimization_viewer(CONFIGURATION_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `VariableViewer` tool to see the optimization results for all variables of the system by loading the .xml output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oad.variable_viewer(MDO_OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running the LCA on an existing design\n",
    "For instance, you may want to change the UAV's lifetime or the electricity mix to study the effect of these parameters on the environmental impacts.\n",
    "\n",
    "First, we load the configuration file containing only the LCA module:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we generate the input file for the LCA based on the previous output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MDO_OUTPUT_FILE = pth.join(DATA_FOLDER_PATH, 'problem_outputs_lca_mdo.xml')\n",
    "oad.generate_inputs(CONFIGURATION_FILE_LCA_ONLY, MDO_OUTPUT_FILE, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the inputs of the LCA module. You can fill in the new values for the LCA parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = pth.join(WORK_FOLDER_PATH, \"problem_inputs.xml\")\n",
    "oad.variable_viewer(INPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the LCA module with the updated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_problem = oad.evaluate_problem(CONFIGURATION_FILE_LCA_ONLY, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_FILE = pth.join(WORK_FOLDER_PATH, \"problem_outputs.xml\")\n",
    "LCA_OUTPUT_FILE = pth.join(DATA_FOLDER_PATH, 'problem_outputs_lca.xml')\n",
    "shutil.copy(OUTPUT_FILE, LCA_OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oad.variable_viewer(LCA_OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Analysis and plots\n",
    "\n",
    "You can now use postprocessing plots to visualize the results of the MDO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1 - Geometry and mass breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = multirotor_geometry_plot(MDO_OUTPUT_FILE, name=\"Drone MDO\")\n",
    "fig.show()\n",
    "#plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = mass_breakdown_sun_plot_drone(MDO_OUTPUT_FILE)\n",
    "fig.show()\n",
    "#plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 - LCA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Weighted single score\n",
    "fig = lca_plot(OUTPUT_FILE, result_step = 'aggregation', filter_option = 'default', filter_level = 1)\n",
    "fig.update_layout(\n",
    "    title=None,\n",
    "    margin=dict(l=10, r=10, t=0, b=0),\n",
    "    width=350,\n",
    "    height=280\n",
    ")\n",
    "colors = [px.colors.qualitative.Plotly[0], px.colors.qualitative.Plotly[9]]\n",
    "fig.update_traces(marker=dict(colors=colors))\n",
    "fig.update_traces(texttemplate='%{label} %{percent:.0%}')\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Weighted single score\n",
    "fig = lca_plot(OUTPUT_FILE, result_step = 'aggregation', filter_option = 'exact', filter_level = 2)\n",
    "fig.update_layout(\n",
    "    title=None,\n",
    "    margin=dict(l=10, r=10, t=0, b=0),\n",
    "    width=350,\n",
    "    height=280\n",
    ")\n",
    "colors = [px.colors.qualitative.Plotly[i] for i in range(1,10)]\n",
    "fig.update_traces(marker=dict(colors=colors))\n",
    "fig.update_traces(texttemplate='%{label} %{percent:.0%}')\n",
    "fig.show()\n",
    "#plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalized and weighted scores for each impact category\n",
    "fig = lca_plot(OUTPUT_FILE, result_step = 'weighting', filter_option = 'default', filter_level = 2, percent = False)\n",
    "fig.update_layout(title=None, width=1000, height=800, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), legend_traceorder=\"reversed\")\n",
    "fig.update_xaxes(showline=True, linewidth=0.5, linecolor='black', tickangle=90)\n",
    "fig.update_yaxes(title='Points', showline=True, linewidth=1, linecolor='black', gridcolor='grey', gridwidth=0.05)\n",
    "\n",
    "for idx in range(len(fig.data)):\n",
    "    fig.data[idx].x = [s.split(\"<br>\", 2)[1] for s in fig.data[idx].x]\n",
    "    fig.data[idx].marker.line.width = 0\n",
    "    \n",
    "#y_errors = [0.0010183, 0.0010032, 0.0521486, 0.0014123, 0.0066393, 0.0002067, 0.0003722, 0.0518777, 0.0006717858, 0.0090101, 0.0000846, 0.0461122, 0.0000046, 0.0014748, 0.0004816, 0.0014202]\n",
    "#fig.data[-1].error_y=dict(type=\"data\", array=y_errors)\n",
    "\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processes contributions in each impact category\n",
    "fig = lca_plot(OUTPUT_FILE, result_step = 'characterization', filter_option = 'default', filter_level = 2, percent = True)\n",
    "\n",
    "fig.update_layout(title=None, width=1000, height=920, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), legend_traceorder=\"reversed\")\n",
    "fig.update_xaxes(showline=True, linewidth=0.5, linecolor='black', tickangle=90)\n",
    "fig.update_yaxes(title='Relative share', showline=True, linewidth=1, linecolor='black', gridcolor='grey', gridwidth=0.05)\n",
    "\n",
    "for idx in range(len(fig.data)):\n",
    "    fig.data[idx].x = [(s.split(\"<br>\")[1] + \" \" + s.split(\"<br>\")[3]).replace(\"/FU\", \"\").replace(\"dimensionless\", \"soil quality index\") for s in fig.data[idx].x]\n",
    "    fig.data[idx].marker.line.width = 0\n",
    "    \n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Splitting \"operation\" contribution into terms related to the components' masses and efficiencies.**\n",
    "\n",
    "This analysis of the specific component contributions is only valid for cruise conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figs = lca_specific_contributions(OUTPUT_FILE, result_step = 'aggregation')\n",
    "for fig in figs:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bar plot export\n",
    "fig = lca_specific_contributions(OUTPUT_FILE, result_step = 'aggregation')[0]\n",
    "\n",
    "for idx in range(len(fig.data)):\n",
    "    if fig.data[idx].legendgroup == 'bar plot':# remove 'payload' and 'misc' from bar plot\n",
    "        fig.data[idx].y = [fig.data[idx].y[i] for i in range(len(fig.data[idx].x)) if fig.data[idx].x[i] not in ['payload', 'misc']] \n",
    "        fig.data[idx].x = [fig.data[idx].x[i] for i in range(len(fig.data[idx].x)) if fig.data[idx].x[i] not in ['payload', 'misc']]\n",
    "fig.data = [fig.data[idx] for idx in range(len(fig.data)) if fig.data[idx].name not in ['payload', 'misc']]  # remove from ternary plot\n",
    "\n",
    "import matplotlib.colors\n",
    "#colors = [px.colors.qualitative.T10[2], px.colors.qualitative.D3[7], px.colors.qualitative.Plotly[9]]\n",
    "colors = [px.colors.qualitative.Plotly[i] for i in range(1, 6)]\n",
    "opacities = [0.2, 0.5, 1.0]\n",
    "patterns = [\"x\", \".\", \"/\"]\n",
    "fig_bar = go.Figure(data=[fig.data[idx] for idx in range(len(fig.data)) if fig.data[idx].legendgroup == 'bar plot'])\n",
    "fig_bar.update_layout(title=None, width=600, height=400, \n",
    "                      paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', \n",
    "                      font=dict(size=14), margin=dict(l=10, r=10, t=5, b=5), \n",
    "                      barmode='stack', xaxis={'categoryorder': 'total descending'},\n",
    "                      showlegend=True\n",
    "                     )\n",
    "for idx in range(len(fig_bar.data)):\n",
    "    fig_bar.data[idx].marker.color = ['rgba' + str(matplotlib.colors.to_rgb(color) + (opacities[idx],)).replace('1.0', '0.99') for color in colors]\n",
    "    fig_bar.data[idx].marker.line.width = 0.8\n",
    "    fig_bar.data[idx].marker.line.color = 'black'\n",
    "    fig_bar.data[idx].marker.pattern.shape = [patterns[idx] for i in range(1,6)]\n",
    "fig_bar.update_xaxes(showline=True, linewidth=0.5, linecolor='black', tickangle= 45)\n",
    "fig_bar.update_yaxes(title='Single score (points)', showline=True, linewidth=1, linecolor='black', gridcolor='grey', gridwidth=0.05, range=[0.0, 0.05])\n",
    "fig_bar.update_traces(showlegend=False).add_traces(\n",
    "    [\n",
    "        go.Bar(name=key, x=[None], marker_color=val[0], showlegend=True, marker_pattern_shape=val[1])\n",
    "        for key, val in {\"mass\": ['rgba(.0, .0, .0, 0.05)', \"x\"],\n",
    "                         \"efficiency\": ['rgba(.0, .0, .0, 0.12)', \".\"],\n",
    "                         \"production\": ['rgba(.0, .0, .0, 0.3)', \"/\"],\n",
    "                        }.items()\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig_bar.show()\n",
    "plotly.io.write_image(fig_bar, 'output_file.pdf', format='pdf', scale=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ternary plot export\n",
    "fig_ternary = go.Figure(data=[fig.data[idx] for idx in range(len(fig.data)) if fig.data[idx].legendgroup == 'ternary plot'])\n",
    "for idx in range(len(fig_ternary.data)):\n",
    "    fig_ternary.data[idx].marker.size *= 12\n",
    "fig_ternary.update_layout(title=None, width=600, height=400, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), legend=dict(itemsizing='constant'), margin=dict(l=50, r=50, t=50, b=50))\n",
    "fig_ternary.update_ternaries(bgcolor='rgba(0,0,0,0)', \n",
    "                             aaxis_linecolor='black',\n",
    "                             baxis_linecolor='black',\n",
    "                             caxis_linecolor='black',\n",
    "                             aaxis_gridcolor='lightgrey', \n",
    "                             baxis_gridcolor='lightgrey', \n",
    "                             caxis_gridcolor='lightgrey', \n",
    "                             aaxis_gridwidth=0.01,\n",
    "                             baxis_gridwidth=0.01,\n",
    "                             caxis_gridwidth=0.01,\n",
    "                             sum=1,\n",
    "                             aaxis_title= 'Mass', \n",
    "                             baxis_title= 'Efficiency', \n",
    "                             caxis_title= 'Production',\n",
    "                             aaxis_ticks='outside',\n",
    "                             baxis_ticks='outside',\n",
    "                             caxis_ticks='outside',\n",
    "                            )\n",
    "colors = [px.colors.qualitative.Plotly[i] for i in range(1, 10)]\n",
    "for idx in range(len(fig_ternary.data)):\n",
    "    fig_ternary.data[idx].marker.color = colors[idx]\n",
    "    fig_ternary.data[idx].marker.line.width = 0.8\n",
    "    fig_ternary.data[idx].marker.line.color = 'black'\n",
    "\n",
    "fig_ternary.show()\n",
    "plotly.io.write_image(fig_ternary, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figs = lca_specific_contributions(OUTPUT_FILE, result_step = 'characterization')\n",
    "for fig in figs:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.3 - Advanced LCA studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all activities created in LCA module\n",
    "activities = get_lca_activities()\n",
    "activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select top-level activity (model)\n",
    "model = get_lca_main_activity()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a particular activity\n",
    "from fastuav.constants import LCA_USER_DB\n",
    "act = lcalg.getActByCode(LCA_USER_DB, 'production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Another way of visualizing interactions\n",
    "recursive_activities(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list available parameters\n",
    "list_lca_parameters()  # returns HTML table\n",
    "# lcalg.params._variable_params()  # returns dictionnary of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 1 - Uncertainty analysis with Monte Carlo\n",
    "\n",
    "The vanilla Monte Carlo from brightway2 is used to calculate the uncertainty on each impact. Only uncertainties from EcoInvent datasets are taken into account. No uncertainty on characterization factors is provided by standard methods. Finally, values from algebraic parameters (e.g., components masses) are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lca_algebraic import multiLCA\n",
    "res = multiLCA(model, methods, **parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastoad.io import VariableIO\n",
    "from fastuav.constants import LCA_PARAM_KEY, LCA_DEFAULT_METHOD\n",
    "import time\n",
    "\n",
    "# Select model\n",
    "model = get_lca_main_activity()  # top-level model\n",
    "\n",
    "# Get parameters values from problem outputs\n",
    "variables = VariableIO(OUTPUT_FILE).read()\n",
    "param_names = [p for p in variables.names() if p.startswith(LCA_PARAM_KEY)]\n",
    "parameters = {}\n",
    "for p in param_names:\n",
    "    parameters[p.replace(LCA_PARAM_KEY, \"\")] = variables[p].value[0]\n",
    "\n",
    "# Run Monte Carlo\n",
    "methods = [eval(m) for m in LCA_DEFAULT_METHOD]\n",
    "res = lca_monte_carlo(\n",
    "    model, # the model\n",
    "    methods, # impacts to assess \n",
    "\n",
    "    # Number of Monte Carlo runs\n",
    "    n_runs=1000, \n",
    "    \n",
    "    # Whether uncertainty on characterization factors is taken into account or not\n",
    "    cfs_uncertainty = False,\n",
    "\n",
    "    # Parameters of the model\n",
    "    **parameters\n",
    ")\n",
    "res.to_csv(\"./workdir/lca_monte_carlo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastoad.io import VariableIO\n",
    "from fastuav.constants import LCA_PARAM_KEY, LCA_DEFAULT_METHOD\n",
    "import time\n",
    "\n",
    "# Select model\n",
    "model = get_lca_main_activity()  # top-level model\n",
    "\n",
    "# Get parameters values from problem outputs\n",
    "variables = VariableIO(OUTPUT_FILE).read()\n",
    "param_names = [p for p in variables.names() if p.startswith(LCA_PARAM_KEY)]\n",
    "parameters = {}\n",
    "for p in param_names:\n",
    "    parameters[p.replace(LCA_PARAM_KEY, \"\")] = variables[p].value[0]\n",
    "\n",
    "# Run Monte Carlo\n",
    "methods = [eval(m) for m in LCA_DEFAULT_METHOD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./workdir/lca_monte_carlo.csv\", header=[0,1,2], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.quantile([0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot distributions\n",
    "fig = make_subplots(rows=4, cols=4, subplot_titles=[s[1].replace(':', '<br>') for s in df.columns.tolist()], horizontal_spacing = 0.08, vertical_spacing = 0.13)\n",
    "axes_units=[r\"$mol H^+_{eq}$\", r\"$kgCO_{2eq}$\", '$CTU_e$', \"$MJ$\", r\"$kgP_{eq}$\", r\"$kgN_{eq}$\", r\"$mol N_{eq}$\", \"$CTUh$\", \"$CTUh$\", r\"$kBq U235_{eq}$\", r\"$\\text{soil quality index}$\", r\"$kg Sb_{eq}$\", r\"$kg CFC-11_{eq}$\", r\"$\\text{disease incidence}$\", r\"$kg NMVOC_{eq}$\", r\"$m^3 \\text{ world eq. deprived}$\"]\n",
    "deterministic_values = [4.741456481, 502.6635915, 3756.514583, 9683.489122, 0.434746217, 0.608561593, 5.591831523, 1.53206E-06, 2.67813E-05, 214.0044574, 2328.077792, 0.029507826, 1.39928E-05, 2.56764E-05, 1.759051648, 630.7958567]\n",
    "\n",
    "for i in range(len(df.columns)): \n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=df.iloc[:, i], histnorm='probability'),\n",
    "        row=i // 4 + 1, \n",
    "        col=i % 4 + 1,\n",
    "    )\n",
    "    fig.add_vline(x=deterministic_values[i], line_dash = 'dash',\n",
    "                  row=i // 4 + 1, \n",
    "                  col=i % 4 + 1,\n",
    "                 )\n",
    "    fig.update_xaxes(title_text=axes_units[i], row=i // 4 + 1, col=i % 4 + 1, titlefont=dict(size=14))\n",
    "    \n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        fig.update_yaxes(showticklabels=True, matches=f'y{4*i+j+2}', row=i+1, col=j+1)\n",
    "    \n",
    "fig.update_layout(title=None, width=1200, height=1200, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), legend_traceorder=\"reversed\", showlegend=False)\n",
    "fig.update_xaxes(showline=True, linewidth=0.5, linecolor='black')\n",
    "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', titlefont=dict(size=14))\n",
    "fig.update_yaxes(title='probability', col=1)\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2 - Impacts variation with number of cycles\n",
    "\n",
    "A design of experiments is achieved on the LCA parameter `n_cycles_uav` to plot the variations of the environmental impacts with the UAV's lifespan.\n",
    "\n",
    "**Warning:** here no iteration on the design is made. DoE on the design plus the LCA can be made by hand or with a DoE on the whole FAST-UAV model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lca_algebraic as lcalg\n",
    "from fastoad.io import VariableIO\n",
    "from fastuav.constants import LCA_PARAM_KEY, LCA_USER_DB, LCA_DEFAULT_METHOD\n",
    "\n",
    "# Select activities/model to explore\n",
    "model = get_lca_main_activity()\n",
    "operation = lcalg.getActByCode(LCA_USER_DB, 'operation')\n",
    "production = lcalg.getActByCode(LCA_USER_DB, 'production')\n",
    "batteries = lcalg.getActByCode(LCA_USER_DB, 'batteries')\n",
    "propellers = lcalg.getActByCode(LCA_USER_DB, 'propellers')\n",
    "motors = lcalg.getActByCode(LCA_USER_DB, 'motors')\n",
    "controllers = lcalg.getActByCode(LCA_USER_DB, 'controllers')\n",
    "airframe = lcalg.getActByCode(LCA_USER_DB, 'airframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get parameters values from problem outputs\n",
    "variables = VariableIO(OUTPUT_FILE).read()\n",
    "param_names = [p for p in variables.names() if p.startswith(LCA_PARAM_KEY)]\n",
    "parameters = {}\n",
    "for p in param_names:\n",
    "    parameters[p.replace(LCA_PARAM_KEY, \"\")] = variables[p].value[0]\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set non-float parameters\n",
    "parameters['elec_switch_param'] = \"eu\"\n",
    "parameters['battery_type'] = \"si_nmc_811\" # \"si_nmc_811\" # \"lfp\"\n",
    "\n",
    "# Modify parameter of interest\n",
    "parameters['n_cycles_uav'] = list(np.linspace(1.0, 10000.0, 100000)) # list(np.geomspace(100.0, 5000, 10000))\n",
    "\n",
    "# Choose lcia method\n",
    "#method = [('ReCiPe 2016 v1.03, midpoint (E) no LT', 'climate change no LT', 'global warming potential (GWP1000) no LT')]\n",
    "methods = [eval(m) for m in LCA_DEFAULT_METHOD]\n",
    "\n",
    "# activities and sub-activities to evaluate\n",
    "activities = [operation, batteries, propellers, controllers, airframe, motors]\n",
    "\n",
    "# Run LCA. The DoE is automatically performed.\n",
    "dict_df = {}\n",
    "for act in activities:\n",
    "    res = lcalg.multiLCAAlgebric(\n",
    "        model, # The model \n",
    "        methods, # Impacts\n",
    "        \n",
    "        extract_activities=[act],\n",
    "        \n",
    "        # Parameters of the model\n",
    "        **parameters\n",
    "    )\n",
    "    res.index = parameters['n_cycles_uav']\n",
    "    dict_df[act.as_dict()['name']] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute single weighted score (very ugly way of doing that...)\n",
    "for act in activities:\n",
    "    act_name = act.as_dict()['name']\n",
    "    dict_df[act_name]['single_score'] = dict_df[act_name]['EF_v3_1:acidification:accumulated_exceedance_AE[mol H+-Eq]'] / 55.569541230602 * 0.062 \\\n",
    "    + dict_df[act_name]['EF_v3_1:climate_change:global_warming_potential_GWP100[kg CO2-Eq]'] / 8095.52506394406 * 0.2106 \\\n",
    "    + dict_df[act_name]['EF_v3_1:ecotoxicity-_freshwater:comparative_toxic_unit_for_ecosystems_CTUe[CTUe]'] / 42683.1618655979 * 0.0192 \\\n",
    "    + dict_df[act_name]['EF_v3_1:energy_resources-_non-renewable:abiotic_depletion_potential_ADP-_fossil_fuels[MJ, net calorific value]'] / 65004.2596640167 * 0.0832 \\\n",
    "    + dict_df[act_name]['EF_v3_1:eutrophication-_freshwater:fraction_of_nutrients_reaching_freshwater_end_compartment_P[kg P-Eq]'] / 1.60685212828813 * 0.0280 \\\n",
    "    + dict_df[act_name]['EF_v3_1:eutrophication-_marine:fraction_of_nutrients_reaching_marine_end_compartment_N[kg N-Eq]'] / 19.5451815519191 * 0.0296 \\\n",
    "    + dict_df[act_name]['EF_v3_1:eutrophication-_terrestrial:accumulated_exceedance_AE[mol N-Eq]'] / 176.754999788942 * 0.0371 \\\n",
    "    + dict_df[act_name]['EF_v3_1:human_toxicity-_carcinogenic:comparative_toxic_unit_for_human_CTUh[CTUh]'] / 0.000016899507395756 * 0.0213 \\\n",
    "    + dict_df[act_name]['EF_v3_1:human_toxicity-_non-carcinogenic:comparative_toxic_unit_for_human_CTUh[CTUh]'] / 0.000229659215899932 * 0.0184 \\\n",
    "    + dict_df[act_name]['EF_v3_1:ionising_radiation-_human_health:human_exposure_efficiency_relative_to_u235[kBq U235-Eq]'] / 4220.15981253385 * 0.0501 \\\n",
    "    + dict_df[act_name]['EF_v3_1:land_use:soil_quality_index[dimensionless]'] / 819498.182923031 * 0.0794 \\\n",
    "    + dict_df[act_name]['EF_v3_1:material_resources-_metals_minerals:abiotic_depletion_potential_ADP-_elements_ultimate_reserves[kg Sb-Eq]'] / 0.0636402782259556 * 0.0755 \\\n",
    "    + dict_df[act_name]['EF_v3_1:ozone_depletion:ozone_depletion_potential_ODP[kg CFC-11-Eq]'] / 0.0536479905672634 * 0.0631 \\\n",
    "    + dict_df[act_name]['EF_v3_1:particulate_matter_formation:impact_on_human_health[disease incidence]'] / 0.000595386937135986 * 0.0896 \\\n",
    "    + dict_df[act_name]['EF_v3_1:photochemical_oxidant_formation-_human_health:tropospheric_ozone_concentration_increase[kg NMVOC-Eq]'] / 40.6013974614544 * 0.0478 \\\n",
    "    + dict_df[act_name]['EF_v3_1:water_use:user_deprivation_potential_deprivation-weighted_water_consumption[m3 world eq. deprived]'] / 11468.7086407597 * 0.0851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save dataframes to csv files\n",
    "for act in activities:\n",
    "    act_name = act.as_dict()['name']\n",
    "    df_act = dict_df[act_name]\n",
    "    df_act.to_csv(\"./workdir/df_cycles_\" + act_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and save dataframe containing only the single scores for each activity\n",
    "df_merged = pd.concat([dict_df[act.as_dict()['name']][\"single_score\"] for act in activities], axis=1, keys=[act.as_dict()['name'] for act in activities])\n",
    "df_merged.to_csv(\"./workdir/df_cycles_single_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the evolution of the single score with the number of cycles\n",
    "df_merged = pd.read_csv(\"./workdir/df_cycles_single_scores.csv\")\n",
    "activities_names = ['airframe', 'controllers', 'motors', 'propellers', 'operation', 'batteries']\n",
    "colors = [px.colors.qualitative.Plotly[1], px.colors.qualitative.Plotly[3], px.colors.qualitative.Plotly[4], px.colors.qualitative.Plotly[5], px.colors.qualitative.Plotly[0], px.colors.qualitative.Plotly[2]]\n",
    "#fig = px.area(df_merged, x='n_cycles', y=activities_names, groupnorm='percent')\n",
    "fig = px.area(df_merged, x='n_cycles', y=activities_names, groupnorm=None, color_discrete_sequence=colors)\n",
    "fig.update_layout(title=None, width=600, height=360, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), legend_title=\"\", legend_traceorder=\"reversed\", )\n",
    "fig.update_xaxes(title='Number of cycles (-)', showline=True, linewidth=1, linecolor='black', gridcolor='lightgrey', gridwidth=0.01, tickformat=\".f\")#, range=[0,2600])\n",
    "fig.update_yaxes(title='Single score (points)', showline=True, linewidth=1, linecolor='black', gridcolor='lightgrey', gridwidth=0.01)#, range=[0,0.18])\n",
    "#fig.for_each_trace(lambda trace: trace.update(fillcolor = trace.line.color, marker_line_color = 'black', marker_line_width = 1.0))\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# With log scale (not used)\n",
    "#df_merged = pd.read_csv(\"./workdir/df_cycles_single_scores.csv\")\n",
    "#activities_names = ['propellers', 'controllers', 'airframe', 'motors', 'batteries', 'operation']\n",
    "#fig = px.area(df_merged, x='n_cycles', y=activities_names, groupnorm=None)\n",
    "#fig.update_layout(title=None, width=1000, height=600, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), legend_title=\"\", legend_traceorder=\"reversed\")\n",
    "#fig.update_xaxes(title='Number of cycles (-)', showline=True, linewidth=1, linecolor='black', gridcolor='lightgrey', gridwidth=0.01, tickformat=\".f\")\n",
    "#tickvals = np.concatenate((np.arange(0.001, 0.01, 0.001),\n",
    "#                           np.arange(0.01, 0.1, 0.01),\n",
    "#                           np.arange(0.1, 1.1, 0.1)))\n",
    "#ticktext = [str(val) if val in [0.001, 0.01, 0.1, 1] else '' for val in tickvals]\n",
    "#fig.update_yaxes(title='Single score (points)', showline=True, linewidth=1, linecolor='black', gridcolor='lightgrey', gridwidth=0.01, \n",
    "#                 type='log',\n",
    "#                 tickmode=\"array\",\n",
    "#                 tickvals=tickvals,\n",
    "#                 ticktext=ticktext\n",
    "#                )  #tickformat = \".1r\"\n",
    "#fig.show()\n",
    "#plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 3 - Variations of components contributions with number of cycles\n",
    "\n",
    "Here we carry a (simple) design of experiments on the LCA module of FAST-UAV. Although it is more time consuming compared to using lca_algebraic's bundled DoE, it enables to get access to the outputs returned by FAST-UAV. Here, we want to have access to the components' contributions as calculated by the LCA postprocessing module of FAST-UAV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastuav.utils.postprocessing.sensitivity_analysis.sensitivity_analysis import doe_fast\n",
    "\n",
    "# Inputs\n",
    "x_dict = {\n",
    "    \"lca:parameters:n_cycles_uav\": np.linspace(1.0, 10000.0, 1000),\n",
    "         }\n",
    "\n",
    "# Outputs\n",
    "y_list = [\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:airframe',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:airframe:efficiency',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:airframe:mass',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:airframe:production',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:batteries',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:batteries:efficiency',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:batteries:mass',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:batteries:production',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:controllers',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:controllers:efficiency',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:controllers:mass',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:controllers:production',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:motors',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:motors:efficiency',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:motors:mass',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:motors:production',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:payload',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:payload:mass',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:propellers',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:propellers:efficiency',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:propellers:mass',\n",
    "    'lca:postprocessing:aggregation:weighted_single_score:model_per_FU:propellers:production',\n",
    "]\n",
    "\n",
    "# Results of DoE\n",
    "df = doe_fast(\"list\", x_dict, y_list, CONFIGURATION_FILE_LCA_ONLY)  # Run DoE on LCA model\n",
    "df.to_csv('./workdir/df_components_contributions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "df.columns = df.columns.str.replace('lca:postprocessing:aggregation:weighted_single_score:', '')\n",
    "component_name = 'batteries'\n",
    "\n",
    "color = px.colors.qualitative.Plotly[2]\n",
    "opacities = [0.2, 0.5, 1.0]\n",
    "patterns = ['x', '.', '/']\n",
    "fig = px.area(df, x='lca:parameters:n_cycles_uav', \n",
    "              y=['model_per_FU:' + component_name + ':mass', \n",
    "                 'model_per_FU:' + component_name + ':efficiency',\n",
    "                 'model_per_FU:' + component_name + ':production'\n",
    "                ], \n",
    "              groupnorm='fraction',\n",
    "              color_discrete_sequence=[color])\n",
    "newnames = {'model_per_FU:' + component_name + ':efficiency':'efficiency', 'model_per_FU:' + component_name + ':mass':'mass', 'model_per_FU:' + component_name + ':production':'production'}\n",
    "fig.for_each_trace(lambda t: t.update(name = newnames[t.name],\n",
    "                                      legendgroup = newnames[t.name],\n",
    "                                      hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])\n",
    "                                     )\n",
    "                  )\n",
    "for idx in range(len(fig.data)):\n",
    "    fig.data[idx].fillcolor = 'rgba' + str(matplotlib.colors.to_rgb(color) + (opacities[idx],)).replace('1.0', '0.99')\n",
    "    fig.data[idx].line.width = 1.2\n",
    "    fig.data[idx].line.color = 'black'\n",
    "    fig.data[idx].fillpattern.shape = patterns[idx]\n",
    "fig.add_annotation(x=9500, y=0.6,\n",
    "            text=\"production\",\n",
    "            showarrow=True,\n",
    "            ax=80,\n",
    "            ay=0,\n",
    "            arrowsize=1.5,\n",
    "            arrowhead=1)\n",
    "fig.add_annotation(x=9500, y=0.06,\n",
    "            text=\"efficiency\",\n",
    "            showarrow=True,\n",
    "            ax=80,\n",
    "            ay=-40,\n",
    "            arrowsize=1.5,\n",
    "            arrowhead=1)\n",
    "fig.add_annotation(x=9500, y=0.015,\n",
    "            text=\"mass\",\n",
    "            showarrow=True,\n",
    "            ax=65,\n",
    "            ay=-10,\n",
    "            arrowsize=1.5,\n",
    "            arrowhead=1)\n",
    "fig.update_layout(title=None, width=600, height=350, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), legend_title=\"\", legend_traceorder=\"reversed\", showlegend=False)\n",
    "fig.update_xaxes(title='Number of cycles (-)', showline=True, linewidth=1, linecolor='black', tickformat=\".f\", showgrid=False, gridwidth=0.0, tickvals=[0, 2000, 4000, 6000, 8000, 10000], ticks=\"outside\") #, range=[0,10000])\n",
    "fig.update_yaxes(title='Single score', showline=True, linewidth=1, linecolor='black', tickformat='.0%', showgrid=False, gridwidth=0.0, range=[0,1.0])\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf', scale=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4 - Optimization Paretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create DataFrame to store points of Pareto\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fresh start\n",
    "oad.generate_configuration_file(\n",
    "    CONFIGURATION_FILE, overwrite=True, distribution_name=\"fastuav\", sample_file_name=\"multirotor_mdo_lca.yaml\"\n",
    ")\n",
    "oad.generate_inputs(CONFIGURATION_FILE, SOURCE_FILE, overwrite=True)\n",
    "INPUT_FILE = pth.join(WORK_FOLDER_PATH, \"problem_inputs.xml\")\n",
    "datafile = oad.DataFile(INPUT_FILE)\n",
    "#datafile.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MTOW minimization objective --> get minimum MTOW value (first extremum of Pareto)\n",
    "\n",
    "# Declare optimization problem\n",
    "conf = oad.FASTOADProblemConfigurator(CONFIGURATION_FILE)\n",
    "prob_definition = conf.get_optimization_definition()\n",
    "prob_definition['objective'] = {'data:weight:mtow': {\n",
    "    'name': 'data:weight:mtow',\n",
    "    'scaler': 0.1}}\n",
    "conf.set_optimization_definition(prob_definition)\n",
    "prob = conf.get_problem(read_inputs=True, auto_scaling=False)\n",
    "\n",
    "# Attach recorder to the driver\n",
    "if os.path.exists(\"cases.sql\"):\n",
    "    os.remove(\"cases.sql\")\n",
    "prob.driver.add_recorder(om.SqliteRecorder(\"cases.sql\"))\n",
    "prob.driver.recording_options[\"includes\"] = ['*']  # include all variables from the problem\n",
    "\n",
    "# Run problem\n",
    "prob.setup()  # setup problem\n",
    "prob.optim_failed = prob.run_driver()  # run optimization\n",
    "prob.cleanup()\n",
    "\n",
    "# Get results from recorded cases and store them\n",
    "cr = om.CaseReader(\"cases.sql\")\n",
    "case = cr.get_case(-1)\n",
    "values = {key:case.outputs[key] for key in case.outputs if case.outputs[key].shape == (1,)}  # get one-dimensional variables\n",
    "df = pd.concat([df, pd.DataFrame(values)], ignore_index=True)  # store in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Energy minimization objective (second extremum of Pareto)\n",
    "\n",
    "# Declare optimization problem\n",
    "conf = oad.FASTOADProblemConfigurator(CONFIGURATION_FILE)\n",
    "prob_definition = conf.get_optimization_definition()\n",
    "prob_definition['objective'] = {'mission:operational:energy': {\n",
    "    'name': 'mission:operational:energy',\n",
    "    'scaler': 0.001}}\n",
    "conf.set_optimization_definition(prob_definition)\n",
    "prob = conf.get_problem(read_inputs=True, auto_scaling=False)\n",
    "prob.driver = om.ScipyOptimizeDriver(tol=1e-4, optimizer='SLSQP', maxiter=30)\n",
    "\n",
    "# Attach recorder to the driver\n",
    "if os.path.exists(\"cases.sql\"):\n",
    "    os.remove(\"cases.sql\")\n",
    "prob.driver.add_recorder(om.SqliteRecorder(\"cases.sql\"))\n",
    "prob.driver.recording_options[\"includes\"] = ['*'] \n",
    "\n",
    "# Run problem\n",
    "prob.setup()  # setup problem\n",
    "prob.optim_failed = prob.run_driver()  # run optimization\n",
    "prob.cleanup()\n",
    "\n",
    "# Get results from recorded cases and store them\n",
    "cr = om.CaseReader(\"cases.sql\")\n",
    "case = cr.get_case(-1)\n",
    "values = {key:case.outputs[key] for key in case.outputs if case.outputs[key].shape == (1,)}  # get one-dimensional variables\n",
    "df = pd.concat([df, pd.DataFrame(values)], ignore_index=True)  # store in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LCA score minimization objective (intermediate extremum of Pareto)\n",
    "\n",
    "# Declare optimization problem\n",
    "conf = oad.FASTOADProblemConfigurator(CONFIGURATION_FILE)\n",
    "prob_definition = conf.get_optimization_definition()\n",
    "prob_definition['objective'] = {'lca:aggregation:weighted_single_score:model_per_FU': {\n",
    "    'name': 'lca:aggregation:weighted_single_score:model_per_FU',\n",
    "    'scaler': 10.0}}\n",
    "conf.set_optimization_definition(prob_definition)\n",
    "prob = conf.get_problem(read_inputs=True, auto_scaling=False)\n",
    "prob.driver = om.ScipyOptimizeDriver(tol=1e-4, optimizer='SLSQP', maxiter=30)\n",
    "\n",
    "# Attach recorder to the driver\n",
    "if os.path.exists(\"cases.sql\"):\n",
    "    os.remove(\"cases.sql\")\n",
    "prob.driver.add_recorder(om.SqliteRecorder(\"cases.sql\"))\n",
    "prob.driver.recording_options[\"includes\"] = ['*'] \n",
    "\n",
    "# Run problem\n",
    "prob.setup()  # setup problem\n",
    "prob.optim_failed = prob.run_driver()  # run optimization\n",
    "prob.cleanup()\n",
    "\n",
    "# Get results from recorded cases and store them\n",
    "cr = om.CaseReader(\"cases.sql\")\n",
    "case = cr.get_case(-1)\n",
    "values = {key:case.outputs[key] for key in case.outputs if case.outputs[key].shape == (1,)}  # get one-dimensional variables\n",
    "df = pd.concat([df, pd.DataFrame(values)], ignore_index=True)  # store in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DoE between the two optimums to construct the Pareto front\n",
    "\n",
    "# Setup\n",
    "num_points = 20\n",
    "mtow_array = np.linspace(min(df['data:weight:mtow']), max(df['data:weight:mtow']), num_points+2)[1:-1]  # don't need to re-run the two extreme cases\n",
    "\n",
    "# Declare optimization problem\n",
    "conf = oad.FASTOADProblemConfigurator(CONFIGURATION_FILE)\n",
    "prob_definition = conf.get_optimization_definition()\n",
    "\n",
    "#prob_definition['objective'] = {'lca:aggregation:weighted_single_score:model_per_FU': {\n",
    "#    'name': 'lca:aggregation:weighted_single_score:model_per_FU',\n",
    "#    'scaler': 10.0}}\n",
    "prob_definition['objective'] = {'mission:operational:energy': {\n",
    "    'name': 'mission:operational:energy',\n",
    "    'scaler': 0.001}}\n",
    "prob_definition['constraints']['data:weight:mtow:requirement:constraint'] = {\n",
    "    'name': 'data:weight:mtow:requirement:constraint',\n",
    "    'lower': 0.0}\n",
    "conf.set_optimization_definition(prob_definition)\n",
    "prob = conf.get_problem(read_inputs=True, auto_scaling=False)\n",
    "prob.driver = om.ScipyOptimizeDriver(tol=1e-4, optimizer='SLSQP', maxiter=30)\n",
    "\n",
    "for mtow in mtow_array:\n",
    "    # Set mtow constraint\n",
    "    datafile['data:weight:mtow:requirement'].val = mtow\n",
    "    datafile.save()\n",
    "    \n",
    "    # Attach recorder to the driver\n",
    "    if os.path.exists(\"cases.sql\"):\n",
    "        os.remove(\"cases.sql\")\n",
    "    prob.driver.add_recorder(om.SqliteRecorder(\"cases.sql\"))\n",
    "    prob.driver.recording_options[\"includes\"] = ['*'] \n",
    "    \n",
    "    # run problem\n",
    "    prob.setup()  # setup problem\n",
    "    prob.optim_failed = prob.run_driver()  # run optimization\n",
    "    prob.cleanup()\n",
    "    \n",
    "    # Get results from recorded cases and store them\n",
    "    cr = om.CaseReader(\"cases.sql\")\n",
    "    case = cr.get_case(-1)\n",
    "    values = {key:case.outputs[key] for key in case.outputs if case.outputs[key].shape == (1,)}  # get one-dimensional variables\n",
    "    df = pd.concat([df, pd.DataFrame(values)], ignore_index=True)  # store in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[['lca:parameters:n_cycles_uav', 'data:weight:mtow', 'lca:aggregation:weighted_single_score:model_per_FU', 'mission:operational:energy', 'data:weight:mtow:requirement', 'data:weight:mtow:requirement:constraint', 'lca:parameters:mass_batteries']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('./workdir/df_pareto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check consistency between energy and lca pareto fronts\n",
    "\n",
    "# Import dataframes\n",
    "df_lca = pd.read_csv('./workdir/df_pareto_lca.csv')\n",
    "df_lca = df_lca.sort_values(by='data:weight:mtow')\n",
    "df_energy = pd.read_csv('./workdir/df_pareto_energy.csv')\n",
    "df_energy = df_energy.sort_values(by='data:weight:mtow')\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df_lca['data:weight:mtow'], y=df_lca['lca:aggregation:weighted_single_score:model_per_FU'], name=\"LCA optim.\", \n",
    "               line_shape='spline', line_dash='solid', mode='lines+markers'),\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df_energy['data:weight:mtow'], y=df_energy['lca:aggregation:weighted_single_score:model_per_FU'], name=\"Energy optim.\", \n",
    "               line_shape='spline', line_dash='solid', mode='lines+markers'),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Import dataframes\n",
    "#df_lca = pd.read_csv('./workdir/df_pareto_lca.csv')\n",
    "#df_lca = df_lca.sort_values(by='data:weight:mtow')\n",
    "#df_energy = pd.read_csv('./workdir/df_pareto_energy.csv')\n",
    "#df_energy = df_energy.sort_values(by='data:weight:mtow')\n",
    "# After checking that both dataframe return the same results, we can keep a single one for plotting\n",
    "#df = df_energy\n",
    "df = pd.read_csv('./workdir/df_pareto.csv')\n",
    "df = df.sort_values(by='data:weight:mtow')\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df['data:weight:mtow'], y=df['lca:aggregation:weighted_single_score:model_per_FU'], name=\"LCA score\", \n",
    "               line_shape='spline', line_dash='solid', mode='lines', marker_symbol='x', line_width=3.0),\n",
    "    secondary_y=False,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df['data:weight:mtow'], y=df['mission:operational:energy'], name=\"Energy consumption\", \n",
    "               line_shape='spline', line_dash='dashdot', mode='lines', line_width=3.0),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Min. mass\n",
    "fig.add_shape(type=\"line\", \n",
    "              x0=df['data:weight:mtow'].min(), y0=0.125, \n",
    "              x1=df['data:weight:mtow'].min(), y1=df['lca:aggregation:weighted_single_score:model_per_FU'].max(), \n",
    "              line_width=1, line_dash=\"dot\", line_color=\"black\")\n",
    "#fig.add_shape(type=\"line\", \n",
    "#              x0=5.35, y0=df['lca:aggregation:weighted_single_score:model_per_FU'].max(), \n",
    "#              x1=df['data:weight:mtow'].min(), y1=df['lca:aggregation:weighted_single_score:model_per_FU'].max(), \n",
    "#              line_width=1, line_dash=\"dot\", line_color=\"black\")\n",
    "fig.add_annotation(y=0.14, x=df['data:weight:mtow'].min(), ay=10, text=\"min. mass\", font=dict(color='black'), textangle=-90)\n",
    "\n",
    "# Min. energy\n",
    "fig.add_shape(type=\"line\", \n",
    "              x0=df.loc[df['mission:operational:energy'].idxmin(), :]['data:weight:mtow'], \n",
    "              y0=df['mission:operational:energy'].min(), \n",
    "              x1=5.37, \n",
    "              y1=df['mission:operational:energy'].min(), \n",
    "              line_width=1, line_dash=\"dot\", line_color=\"red\", yref='y2')\n",
    "fig.add_shape(type=\"line\", \n",
    "              x0=df.loc[df['mission:operational:energy'].idxmin(), :]['data:weight:mtow'], \n",
    "              y0=620, \n",
    "              x1=df.loc[df['mission:operational:energy'].idxmin(), :]['data:weight:mtow'], \n",
    "              y1=df['mission:operational:energy'].min(), \n",
    "              line_width=1, line_dash=\"dot\", line_color=\"red\", yref='y2')\n",
    "fig.add_annotation(x=5.28, y=df['mission:operational:energy'].min(), ay=-10, text=\"min. energy\", yref='y2', font=dict(color='red'))\n",
    "\n",
    "# Min. impact\n",
    "fig.add_shape(type=\"line\", \n",
    "              x0=4.23, \n",
    "              y0=df['lca:aggregation:weighted_single_score:model_per_FU'].min(), \n",
    "              x1=df.loc[df['lca:aggregation:weighted_single_score:model_per_FU'].idxmin(), :]['data:weight:mtow'], \n",
    "              y1=df['lca:aggregation:weighted_single_score:model_per_FU'].min(), \n",
    "              line_width=1, line_dash=\"dot\", line_color=\"blue\")\n",
    "fig.add_shape(type=\"line\", \n",
    "              x0=df.loc[df['lca:aggregation:weighted_single_score:model_per_FU'].idxmin(), :]['data:weight:mtow'], \n",
    "              y0=0.125, \n",
    "              x1=df.loc[df['lca:aggregation:weighted_single_score:model_per_FU'].idxmin(), :]['data:weight:mtow'], \n",
    "              y1=df['lca:aggregation:weighted_single_score:model_per_FU'].min(), \n",
    "              line_width=1, line_dash=\"dot\", line_color=\"blue\")\n",
    "fig.add_annotation(x=4.38, y=df['lca:aggregation:weighted_single_score:model_per_FU'].min(), ay=-10, text=\"min. impact\", font=dict(color='blue'))\n",
    "\n",
    "\n",
    "# Add figure title\n",
    "fig.update_layout(title=None, width=600, height=400, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), margin=dict(l=10, r=10, t=5, b=5),\n",
    "                  legend=dict(x=.5,\n",
    "                              y=.9,\n",
    "                              traceorder=\"normal\",\n",
    "                            )\n",
    "                 )\n",
    "fig.update_xaxes(title_text='UAV mass (kg)', showline=True, linewidth=1.0, linecolor='black', showgrid=False, ticks='outside')\n",
    "fig.update_yaxes(showline=True, linewidth=1, showgrid=False, ticks='outside')\n",
    "#fig.update_yaxes(range=[0.07666, 0.08658], secondary_y=False)\n",
    "#fig.update_yaxes(range=[790, 945], secondary_y=True)\n",
    "#fig.update_xaxes(range=[5.555, 6.35])\n",
    "fig.update_yaxes(title_text=\"LCA single score (points)\", secondary_y=False, \n",
    "                 titlefont=dict(color='blue'),  tickfont=dict(color='blue'), linecolor='blue',\n",
    "                )\n",
    "fig.update_yaxes(title_text=\"Mission energy consumption (kJ)\", secondary_y=True, titlefont=dict(color='red'),  tickfont=dict(color='red'), linecolor='red')\n",
    "\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DESIGN PARAMETERS VARIATION: propeller diameter, battery mass, ...\n",
    "df = pd.read_csv('./workdir/df_pareto.csv')\n",
    "df = df.sort_values(by='data:weight:mtow')\n",
    "\n",
    "# Normalize w.r.t. mass minimization design\n",
    "df['data:weight:airframe:mass'] = df['data:weight:airframe:arms:mass'] + df['data:weight:airframe:body:mass']\n",
    "df_norm = df/df.loc[0,:]\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df['data:weight:mtow'], \n",
    "               y=df_norm['data:weight:propulsion:multirotor:battery:mass'], \n",
    "               name=\"Battery mass\", line_shape='spline', mode='lines', line_width=3),\n",
    "    secondary_y=False,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df['data:weight:mtow'], \n",
    "               y=df_norm['data:weight:propulsion:multirotor:motor:mass'], \n",
    "               name=\"Motor mass\", line_shape='spline', mode='lines', line_dash='dot', line_width=3),\n",
    "    secondary_y=False,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df['data:weight:mtow'], \n",
    "               y=df_norm['data:weight:airframe:mass'], \n",
    "               name=\"Airframe mass\", line_shape='spline', mode='lines', line_dash='dashdot', line_width=3),\n",
    "    secondary_y=False,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df['data:weight:mtow'], \n",
    "               y=df_norm['data:propulsion:multirotor:propeller:diameter'], \n",
    "               name=\"Propeller diameter\", line_shape='spline', mode='lines', line_dash='dash', line_width=3),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_shape(type=\"line\", \n",
    "              x0=df['data:weight:mtow'].min(), y0=.8, \n",
    "              x1=df['data:weight:mtow'].min(), y1=2.0, \n",
    "              line_width=1, line_dash=\"dot\", line_color=\"black\")\n",
    "fig.add_annotation(y=1.0, x=df['data:weight:mtow'].min(), ay=0, text=\"min. mass\", font=dict(color='black'), textangle=-90)\n",
    "fig.add_shape(type=\"line\", \n",
    "              x0=df['data:weight:mtow'].max(), y0=.8, \n",
    "              x1=df['data:weight:mtow'].max(), y1=2.0, \n",
    "              line_width=1, line_dash=\"dot\", line_color=\"black\")\n",
    "fig.add_annotation(y=1.0, x=df['data:weight:mtow'].max(), ay=0, text=\"min. energy\", font=dict(color='black'), textangle=-90)\n",
    "fig.add_shape(type=\"line\", \n",
    "              x0=5.983233, y0=.8, \n",
    "              x1=5.983233, y1=2.0, \n",
    "              line_width=1, line_dash=\"dot\", line_color=\"black\")\n",
    "fig.add_annotation(y=1.0, x=5.983233, ay=0, text=\"min. impact\", font=dict(color='black'), textangle=-90)\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(title=None, width=600, height=400, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), margin=dict(l=10, r=10, t=5, b=5),\n",
    "                  legend=dict(\n",
    "                        orientation=\"h\",\n",
    "                        yanchor=\"bottom\",\n",
    "                        y=1.0,\n",
    "                        xanchor=\"right\",\n",
    "                        x=0.88,\n",
    "                      font_size=16\n",
    "                    )\n",
    "                 )\n",
    "                 \n",
    "fig.update_xaxes(title_text='UAV mass (kg)', showline=True, linewidth=1.0, linecolor='black', showgrid=False, ticks='outside', range=[5.55, 6.3])\n",
    "fig.update_yaxes(title_text='Design parameter variation (-)', showline=True, linewidth=1, showgrid=True, ticks='outside', linecolor='black', gridcolor='grey', gridwidth=0.05)\n",
    "\n",
    "# Display and save\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COMPARISON OF THE DETAILED LCA SCORES OF FOR THREE OPTIMUM (1/2)\n",
    "\n",
    "OUTPUT_FILE_MASS = pth.join(WORK_FOLDER_PATH, \"problem_outputs_lca_optim_mass.xml\")\n",
    "OUTPUT_FILE_ENERGY = pth.join(WORK_FOLDER_PATH, \"problem_outputs_lca_optim_energy.xml\")\n",
    "OUTPUT_FILE_LCA = pth.join(WORK_FOLDER_PATH, \"problem_outputs_lca_optim_lca.xml\")\n",
    "\n",
    "# FINAL SCORE\n",
    "fig = lca_plot(OUTPUT_FILE_LCA, result_step = 'aggregation', filter_option = 'default', filter_level = 1)\n",
    "fig.update_layout(\n",
    "    title=None,\n",
    "    margin=dict(l=10, r=10, t=0, b=0),\n",
    "    width=350,\n",
    "    height=280\n",
    ")\n",
    "colors = [px.colors.qualitative.Plotly[0], px.colors.qualitative.Plotly[9]]\n",
    "fig.update_traces(marker=dict(colors=colors))\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COMPARISON OF THE DETAILED LCA SCORES OF FOR THREE OPTIMUM (2/2)\n",
    "\n",
    "output_files_dict = {'mass minimization': OUTPUT_FILE_MASS,\n",
    "                     'energy minimization': OUTPUT_FILE_ENERGY,\n",
    "                     'LCA score minimization': OUTPUT_FILE_LCA\n",
    "                    }\n",
    "colors = [px.colors.qualitative.Set1[8], px.colors.qualitative.Plotly[1], px.colors.qualitative.Plotly[0]]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig_data_ref = lca_plot(OUTPUT_FILE_MASS, result_step = 'characterization', filter_option = 'default', filter_level = 0, percent=False).data[0]\n",
    "\n",
    "idx = 0\n",
    "for name, output_file in output_files_dict.items():\n",
    "    fig_data = lca_plot(output_file, result_step = 'characterization', filter_option = 'default', filter_level = 0, percent=False).data[0]\n",
    "    #fig.add_trace(go.Bar(x=fig_data.labels, y=fig_data.values))\n",
    "    fig.add_trace(go.Bar(x=fig_data.x, y=np.asarray(fig_data.y)/np.asarray(fig_data_ref.y), name=name, marker_color=colors[idx]))\n",
    "    idx += 1\n",
    "\n",
    "fig.update_layout(barmode='group')\n",
    "fig.update_layout(title=None, width=850, height=650, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), legend_title_text='UAV Design',\n",
    "                 margin=dict(l=10, r=10, t=0, b=0))\n",
    "fig.update_xaxes(showline=True, linewidth=0.5, linecolor='black', tickangle=90)\n",
    "fig.update_yaxes(title='Relative score', showline=True, linewidth=1, linecolor='black', gridcolor='grey', gridwidth=0.05)\n",
    "\n",
    "for idx in range(len(fig.data)):\n",
    "    fig.data[idx].x = [s.split(\"<br>\", 2)[1] for s in fig.data[idx].x]\n",
    "    fig.data[idx].marker.line.width = 0\n",
    "\n",
    "#for idx in range(len(fig.data)):\n",
    "#    fig.data[idx].x = [s.split(\"<br>\")[1] + \" \" + s.split(\"<br>\")[3] for s in fig.data[idx].x]\n",
    "#    fig.data[idx].marker.line.width = 0\n",
    "    \n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5 - Batteries comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COMPARISON OF THE LCA SCORES\n",
    "\n",
    "OUTPUT_FILE_NMC = pth.join(WORK_FOLDER_PATH, \"problem_outputs_lca_nmc811.xml\")\n",
    "OUTPUT_FILE_LFP = pth.join(WORK_FOLDER_PATH, \"problem_outputs_lca_lfp.xml\")\n",
    "OUTPUT_FILE_SI_NMC = pth.join(WORK_FOLDER_PATH, \"problem_outputs_lca_si_nmc.xml\")\n",
    "\n",
    "output_files_dict = {'G/NMC': OUTPUT_FILE_NMC,\n",
    "                     'G/LFP': OUTPUT_FILE_LFP,\n",
    "                     'Si/NMC': OUTPUT_FILE_SI_NMC\n",
    "                    }\n",
    "colors = [px.colors.qualitative.Set1[8], px.colors.qualitative.Plotly[1], px.colors.qualitative.Plotly[0]]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "idx = 0\n",
    "for name, output_file in output_files_dict.items():\n",
    "    fig_data = lca_plot(output_file, result_step = 'weighting', filter_option = 'default', filter_level = 0, percent=False).data[0]\n",
    "    #fig.add_trace(go.Bar(x=fig_data.labels, y=fig_data.values))\n",
    "    fig.add_trace(go.Bar(x=fig_data.x, y=fig_data.y, name=name, marker_color=colors[idx]))\n",
    "    idx += 1\n",
    "\n",
    "fig.update_layout(barmode='group')\n",
    "fig.update_layout(title=None, width=850, height=650, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), legend_title_text='Battery chemistry',\n",
    "                 margin=dict(l=10, r=10, t=0, b=0))\n",
    "fig.update_xaxes(showline=True, linewidth=0.5, linecolor='black', tickangle=90)\n",
    "fig.update_yaxes(title='Points', showline=True, linewidth=1, linecolor='black', gridcolor='grey', gridwidth=0.05)\n",
    "\n",
    "for idx in range(len(fig.data)):\n",
    "    fig.data[idx].x = [s.split(\"<br>\", 2)[1] for s in fig.data[idx].x]\n",
    "    fig.data[idx].marker.line.width = 0\n",
    "\n",
    "#for idx in range(len(fig.data)):\n",
    "#    fig.data[idx].x = [s.split(\"<br>\")[1] + \" \" + s.split(\"<br>\")[3] for s in fig.data[idx].x]\n",
    "#    fig.data[idx].marker.line.width = 0\n",
    "    \n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COMPARISON OF THE LCA SCORES - NORMALIZED W.R.T BASELINE\n",
    "\n",
    "OUTPUT_FILE_NMC = pth.join(WORK_FOLDER_PATH, \"problem_outputs_lca_nmc811.xml\")\n",
    "OUTPUT_FILE_LFP = pth.join(WORK_FOLDER_PATH, \"problem_outputs_lca_lfp.xml\")\n",
    "OUTPUT_FILE_SI_NMC = pth.join(WORK_FOLDER_PATH, \"problem_outputs_lca_si_nmc.xml\")\n",
    "\n",
    "output_files_dict = {'G/NMC': OUTPUT_FILE_NMC,\n",
    "                     'G/LFP': OUTPUT_FILE_LFP,\n",
    "                     'Si/NMC': OUTPUT_FILE_SI_NMC\n",
    "                    }\n",
    "colors = [px.colors.qualitative.Set1[8], px.colors.qualitative.Plotly[1], px.colors.qualitative.Plotly[0]]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig_data_ref = lca_plot(OUTPUT_FILE_NMC, result_step = 'characterization', filter_option = 'default', filter_level = 0, percent=False).data[0]\n",
    "\n",
    "idx = 0\n",
    "for name, output_file in output_files_dict.items():\n",
    "    fig_data = lca_plot(output_file, result_step = 'characterization', filter_option = 'default', filter_level = 0, percent=False).data[0]\n",
    "    #fig.add_trace(go.Bar(x=fig_data.labels, y=fig_data.values))\n",
    "    fig.add_trace(go.Bar(x=fig_data.x, y=np.asarray(fig_data.y)/np.asarray(fig_data_ref.y), name=name, marker_color=colors[idx]))\n",
    "    idx += 1\n",
    "\n",
    "fig.update_layout(barmode='group')\n",
    "fig.update_layout(title=None, width=850, height=650, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), legend_title_text='Battery chemistry',\n",
    "                 margin=dict(l=10, r=10, t=0, b=0))\n",
    "fig.update_xaxes(showline=True, linewidth=0.5, linecolor='black', tickangle=90)\n",
    "fig.update_yaxes(title='Relative score', showline=True, linewidth=1, linecolor='black', gridcolor='grey', gridwidth=0.05)\n",
    "\n",
    "for idx in range(len(fig.data)):\n",
    "    fig.data[idx].x = [s.split(\"<br>\", 2)[1] for s in fig.data[idx].x]\n",
    "    fig.data[idx].marker.line.width = 0\n",
    "\n",
    "#for idx in range(len(fig.data)):\n",
    "#    fig.data[idx].x = [s.split(\"<br>\")[1] + \" \" + s.split(\"<br>\")[3] for s in fig.data[idx].x]\n",
    "#    fig.data[idx].marker.line.width = 0\n",
    "    \n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIATION WITH NUMBER OF CYCLES\n",
    "df_nmc = pd.read_csv(\"./workdir/df_cycles_single_scores_nmc.csv\")\n",
    "df_lfp = pd.read_csv(\"./workdir/df_cycles_single_scores_lfp.csv\")\n",
    "df_si_nmc = pd.read_csv(\"./workdir/df_cycles_single_scores_si_nmc.csv\")\n",
    "\n",
    "df_nmc['total'] = df_nmc['operation'] + df_nmc['batteries'] + df_nmc['propellers'] + df_nmc['controllers'] + df_nmc['airframe'] + df_nmc['motors']\n",
    "df_lfp['total'] = df_lfp['operation'] + df_lfp['batteries'] + df_lfp['propellers'] + df_lfp['controllers'] + df_lfp['airframe'] + df_lfp['motors']\n",
    "df_si_nmc['total'] = df_si_nmc['operation'] + df_si_nmc['batteries'] + df_si_nmc['propellers'] + df_si_nmc['controllers'] + df_si_nmc['airframe'] + df_si_nmc['motors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_nmc['n_cycles'], y=df_nmc['total'], line=dict(color=px.colors.qualitative.Dark2[7], dash='solid'), name='G/NMC'))\n",
    "fig.add_trace(go.Scatter(x=df_lfp['n_cycles'], y=df_lfp['total'], line=dict(color=px.colors.qualitative.Plotly[1], dash='solid'), name='G/LFP'))\n",
    "fig.add_trace(go.Scatter(x=df_si_nmc['n_cycles'], y=df_si_nmc['total'], line=dict(color=px.colors.qualitative.Plotly[0], dash='solid'), name='Si/NMC'))\n",
    "\n",
    "fig.update_layout(title=None, width=600, height=300, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), \n",
    "                  legend_title_text='Battery chemistry', legend_traceorder=\"reversed\", margin=dict(l=10, r=10, t=0, b=0))\n",
    "fig.update_xaxes(title='Number of cycles (-)', showline=True, linewidth=1, linecolor='black', gridcolor='lightgrey', showgrid=True, gridwidth=0.01, tickformat=\".f\", range=[0,2600])\n",
    "fig.update_yaxes(title='Single score (points)', showline=True, linewidth=1, linecolor='black', gridcolor='lightgrey', showgrid=True, gridwidth=0.01, range=[0,0.17])\n",
    "#fig.for_each_trace(lambda trace: trace.update(fillcolor = trace.line.color, marker_line_color = 'black', marker_line_width = 1.0))\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 6 - Sensitivity to design specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastuav.utils.postprocessing.sensitivity_analysis.sensitivity_analysis import doe_fast\n",
    "\n",
    "# Fresh start\n",
    "oad.generate_configuration_file(\n",
    "    CONFIGURATION_FILE, overwrite=True, distribution_name=\"fastuav\", sample_file_name=\"multirotor_mdo_lca.yaml\"\n",
    ")\n",
    "oad.generate_inputs(CONFIGURATION_FILE, SOURCE_FILE, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace the following code by the \"FullFactorialGenerator\" driver of OpenMDAO...\n",
    "\n",
    "import itertools\n",
    "x_dict = {\n",
    "    \"mission:operational:route_1:payload:mass\": np.linspace(2, 5, 10),\n",
    "    \"mission:operational:route_1:cruise:distance\": np.linspace(3000, 10000, 10),\n",
    "    #\"mission:operational:route_1:cruise:speed\": np.linspace(10, 18, 2)\n",
    "}\n",
    "keys, values = zip(*x_dict.items())\n",
    "permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "case_list = [[(key, val) for key, val in permut_dict.items()] for permut_dict in permutations_dicts]\n",
    "for e in case_list:\n",
    "    e.append(('mission:sizing:payload:mass', e[0][1]))\n",
    "    e.append(('mission:operational:route_2:cruise:distance', e[1][1]))\n",
    "    #e.append(('mission:operational:route_2:cruise:speed', e[2][1])) \n",
    "    x_dict['mission:sizing:payload:mass'] = x_dict['mission:operational:route_1:payload:mass']\n",
    "    x_dict['mission:operational:route_2:cruise:distance'] = x_dict['mission:operational:route_1:cruise:distance']\n",
    "    #x_dict['mission:operational:route_2:cruise:speed'] = x_dict['mission:operational:route_1:cruise:speed']\n",
    "len(case_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_list = ['data:weight:mtow', 'lca:aggregation:weighted_single_score:model_per_FU', \n",
    "          'mission:operational:energy', 'data:weight:airframe:arms:mass', \n",
    "          'data:weight:airframe:body:mass', 'data:weight:propulsion:multirotor:battery:mass', \n",
    "          'data:weight:propulsion:multirotor:esc:mass', 'data:weight:propulsion:multirotor:motor:mass', \n",
    "          'data:weight:propulsion:multirotor:propeller:mass', 'data:geometry:arms:number', 'data:geometry:arms:prop_per_arm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = om.DOEDriver(\n",
    "            om.ListGenerator(\n",
    "                data=case_list\n",
    "            )\n",
    "        )\n",
    "df = doe_fast(\"custom\", x_dict, y_list, CONFIGURATION_FILE, custom_driver=driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONTOUR PLOT\n",
    "df = pd.read_csv('./workdir/sensitivity_analysis/doe_custom.csv')\n",
    "df['mission:operational:route_1:cruise:distance'] /= 1000  # set distance to km\n",
    "n_cycles = 2600\n",
    "df['normalized_fu'] = df['lca:aggregation:weighted_single_score:model_per_FU'] / (n_cycles * df['mission:operational:route_1:payload:mass'] * df['mission:operational:route_1:cruise:distance'])\n",
    "df['operating empty weight'] = df['data:weight:mtow'] - df['mission:operational:route_1:payload:mass']\n",
    "df = df.drop(df[df.optim_failed == 1.0].index)  # drop failed optim points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set variables to plot\n",
    "x_name = 'mission:operational:route_1:payload:mass'\n",
    "y_name = 'mission:operational:route_1:cruise:distance'\n",
    "z_name = 'normalized_fu'\n",
    "\n",
    "# Reshape data into a grid\n",
    "x_vals = sorted(df[x_name].unique())\n",
    "y_vals = sorted(df[y_name].unique())\n",
    "z_grid = df.pivot(index=y_name, columns=x_name, values=z_name).values\n",
    "\n",
    "# Create the contour plot    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Contour(\n",
    "    x=x_vals, y=y_vals, z=z_grid, \n",
    "    connectgaps=True,\n",
    "    contours=dict(start=1.75e-6, end=6.75e-6, size=0.00000025, showlabels=True),\n",
    "    #contours=dict(start=df[z_name].min(), end=df[z_name].max(), size=0.00000025, showlabels=True),\n",
    "    #contours_coloring='heatmap' # can also be 'lines', or 'none'\n",
    "    colorbar=dict(\n",
    "        title='Single score (points/kg.km)', # title here\n",
    "        titleside='right',\n",
    "        titlefont=dict(size=16),\n",
    "        ticks='outside'\n",
    "    ),\n",
    "    colorscale='RdBu_r' # Blackbody,Bluered,Blues,Cividis,Earth,Electric,Greens,Greys,Hot,Jet,Picnic,Portland,Rainbow,RdBu,Reds,Viridis,YlGnBu,YlOrRd. (add '_r' for reversed)\n",
    "))\n",
    "\n",
    "#fig.add_trace(go.Scatter(x=df[x_name], y=df[y_name], mode='markers'))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title=None, width=600, height=400, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14),\n",
    "                 margin=dict(l=10, r=10, t=0, b=0))\n",
    "fig.update_xaxes(title='Payload mass (kg)', ticks='outside', dtick=0.5)\n",
    "fig.update_yaxes(title='Delivery distance (km)', ticks='outside')\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set variables to plot\n",
    "x_name = 'mission:operational:route_1:payload:mass'\n",
    "y_name = 'mission:operational:route_1:cruise:distance'\n",
    "z_name = 'data:weight:mtow'\n",
    "\n",
    "# Reshape data into a grid\n",
    "x_vals = sorted(df[x_name].unique())\n",
    "y_vals = sorted(df[y_name].unique())\n",
    "z_grid = df.pivot(index=y_name, columns=x_name, values=z_name).values\n",
    "\n",
    "# Create the contour plot    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Contour(\n",
    "    x=x_vals, y=y_vals, z=z_grid, \n",
    "    connectgaps=True,\n",
    "    contours=dict(start=2.5, end=18.5, size=1.0, showlabels=True),\n",
    "    #contours=dict(start=df[z_name].min(), end=df[z_name].max(), size=0.5),\n",
    "    #contours_coloring='heatmap' # can also be 'lines', or 'none'\n",
    "    colorbar=dict(\n",
    "        title='UAV total mass, including payload (kg)', # title here\n",
    "        titleside='right',\n",
    "        titlefont=dict(size=16),\n",
    "        ticks='outside'\n",
    "    ),\n",
    "    colorscale='RdBu_r' # Blackbody,Bluered,Blues,Cividis,Earth,Electric,Greens,Greys,Hot,Jet,Picnic,Portland,Rainbow,RdBu,Reds,Viridis,YlGnBu,YlOrRd. (add '_r' for reversed)\n",
    "))\n",
    "\n",
    "#fig.add_trace(go.Scatter(x=df[x_name], y=df[y_name], mode='markers'))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title=None, width=600, height=400, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14),\n",
    "                 margin=dict(l=10, r=10, t=0, b=0))\n",
    "fig.update_xaxes(title='Payload mass (kg)', ticks='outside', dtick=0.5)\n",
    "fig.update_yaxes(title='Delivery distance (km)', ticks='outside')\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set variables to plot\n",
    "x_name = 'mission:operational:route_1:payload:mass'\n",
    "y_name = 'mission:operational:route_1:cruise:distance'\n",
    "z_name = 'operating empty weight'\n",
    "\n",
    "# Reshape data into a grid\n",
    "x_vals = sorted(df[x_name].unique())\n",
    "y_vals = sorted(df[y_name].unique())\n",
    "z_grid = df.pivot(index=y_name, columns=x_name, values=z_name).values\n",
    "\n",
    "# Create the contour plot    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Contour(\n",
    "    x=x_vals, y=y_vals, z=z_grid, \n",
    "    connectgaps=True,\n",
    "    contours=dict(start=2.0, end=12.5, size=0.8, showlabels=True),\n",
    "    #contours=dict(start=df[z_name].min(), end=df[z_name].max(), size=0.5),\n",
    "    #contours_coloring='heatmap' # can also be 'lines', or 'none'\n",
    "    colorbar=dict(\n",
    "        title='UAV mass, excluding payload (kg)', # title here\n",
    "        titleside='right',\n",
    "        titlefont=dict(size=16),\n",
    "        ticks='outside'\n",
    "    ),\n",
    "    colorscale='RdBu_r' # Blackbody,Bluered,Blues,Cividis,Earth,Electric,Greens,Greys,Hot,Jet,Picnic,Portland,Rainbow,RdBu,Reds,Viridis,YlGnBu,YlOrRd. (add '_r' for reversed)\n",
    "))\n",
    "\n",
    "#fig.add_trace(go.Scatter(x=df[x_name], y=df[y_name], mode='markers'))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title=None, width=600, height=400, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14),\n",
    "                 margin=dict(l=10, r=10, t=0, b=0))\n",
    "fig.update_xaxes(title='Payload mass (kg)', ticks='outside', dtick=0.5)\n",
    "fig.update_yaxes(title='Delivery distance (km)', ticks='outside')\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 - Assessment against Planetary Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lca_planetary_boundaries(file_path: str, functional_unit_realizations=None, allocation=None, file_formatter=None):\n",
    "    \"\"\"\n",
    "    Returns a plot of the life cycle results compared to planetary boundaries.\n",
    "    \n",
    "    :param file_path: xml file containing the lca results (typically expressed per kg.km)\n",
    "    :param: functional_unit_realizations: number of functional units (typically, number of kg.km) to assess against planetary boundaries.\n",
    "    :return fig: figure of the life cycle results compared to planetary boundaries, for each category.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(functional_unit_realizations, (list, tuple, np.ndarray)):\n",
    "        functional_unit_realizations = [functional_unit_realizations]\n",
    "\n",
    "    # file containing variables and their values\n",
    "    variables = VariableIO(file_path, file_formatter).read()\n",
    "\n",
    "    # identifier for lca top-level model\n",
    "    model_key = LCA_MODEL_KEY.replace(\" \", \"_\")\n",
    "\n",
    "    # Results to plot : normalized against PBs\n",
    "    RESULTS_KEY = LCA_NORMALIZATION_KEY\n",
    "\n",
    "    # look for method names\n",
    "    methods = {}\n",
    "    for variable in variables:\n",
    "        name = variable.name\n",
    "        if RESULTS_KEY not in name or LCA_FACTOR_KEY in name:\n",
    "            continue\n",
    "        method_name = name.split(RESULTS_KEY)[-1].split(\":\" + model_key)[0]\n",
    "        unit = variable.description  # units for methods are stored in description column rather than units (not handled by openMDAO units object)\n",
    "        methods[method_name] = unit\n",
    "\n",
    "    # Build dataframe of normalized impacts\n",
    "    df = pd.DataFrame()\n",
    "    for method, unit in methods.items():\n",
    "        scores_dict = dict()\n",
    "        for variable in variables.names():\n",
    "            if RESULTS_KEY not in variable or method not in variable or LCA_FACTOR_KEY in variable not in variable or model_key not in variable:\n",
    "                continue\n",
    "            end = variable.find(\":\" + model_key)\n",
    "            full_name = variable[end + 1:] \n",
    "            value = variables[variable].value[0]\n",
    "            scores_dict[full_name] = [value]\n",
    "\n",
    "        unit_str = f'<br>[{unit}]' if unit != '' else ''\n",
    "        df2 = pd.DataFrame(scores_dict,\n",
    "                           index=[method.replace(\"_\", \" \").replace(':', '<br>') + unit_str]).transpose()\n",
    "\n",
    "        df = pd.concat([df, df2], axis=1, ignore_index=False)\n",
    "\n",
    "    # plots\n",
    "    data = []\n",
    "    x = df.columns.values  # each column correspond to an impact assessment method\n",
    "    \n",
    "    # Add polar plots for each functional unit value\n",
    "    f_prev = 0\n",
    "    for idx in range(len(functional_unit_realizations)):\n",
    "        f_current = functional_unit_realizations[idx]\n",
    "        row = df.loc[df.index == model_key]   # Results only for the main model (not the children activities)\n",
    "        y = [row[method][0] * (f_current - f_prev) for method in x] # multiply values by the number of times we want to achieve the functional unit (typically, total number of kg.km), and substract data from previous set to avoid cumulative effect on bar plot\n",
    "        trace=go.Barpolar(\n",
    "            name=str(f_current),\n",
    "            r=y,\n",
    "            theta=x,\n",
    "            #marker=dict(\n",
    "            #    color=y,  # Set the \"r\" values as the color values\n",
    "            #    colorscale='Viridis'  # Choose a colorscale (e.g., 'Viridis')\n",
    "            #)\n",
    "        )\n",
    "        data.append(trace)\n",
    "        f_prev = f_current\n",
    "        \n",
    "    # Add a dashed circle representing allocation budget\n",
    "    if allocation is not None:\n",
    "        circle_theta = np.linspace(0, 2 * np.pi, 100)  # Angular values for the circle\n",
    "        circle_r = np.full(len(x), allocation)  # Set your desired radius here\n",
    "        data.append(go.Scatterpolar(name = 'Proposed allocation', r=circle_r, theta=x, mode='lines', line_shape='spline', line_dash='dash',  fill='toself'))#, fillcolor='rgba(0, 0, 255, 0.2)',))\n",
    "        \n",
    "    fig = go.Figure(data=data)\n",
    "\n",
    "    return fig, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve data file\n",
    "OUTPUT_FILE_PB = pth.join(WORK_FOLDER_PATH, \"problem_outputs_lca_planetary_boundaries.xml\")\n",
    "\n",
    "# Define demand \n",
    "# E.g. one delivery per week of a 2 kg payload over 7.5 km (15 km round-trip), during one year = 1560 (3120 round-trip) kg.km \n",
    "# NB: check how the functional unit is defined (distance = round trip or half? For now, FAST-UAV computes LCA based on total distance so you have to multiply by 2 the delivery distance)\n",
    "#functional_unit_realizations = [(2*12)*(2*7.5), (2*52)*(2*7.5), (2*2*52)*(2*7.5)]  # [2 kg/month, 2 kg/week, 2*2kg/week] on 7.5 km (2*7.5 = 15 km round-trip)\n",
    "functional_unit_realizations = [2*180]  # [2 kg/month] on 7.5 km (2*7.5 = 15 km round-trip)\n",
    "#functional_unit_realizations = [2*336000]  # 336 000 kg.km = last-mile delivery (< 50km) in France in 2019, per capita.\n",
    "#functional_unit_realizations = [(500+100)*(2*7.5)]  # per capita.year: 500kg food consumed + 100 kg waste (packages+food). Assumption = it is transported over 7.5km.\n",
    "#functional_unit_realizations = [(2*12)*(2*7.5), (2*52)*(2*7.5), (500+100)*(2*7.5)]  # [2 kg/week, 600kg food+waste/year] on 7.5 km (2*7.5 = 15 km round-trip)\n",
    "#functional_unit_realizations = [(2*52)*(2*7.5), (500+100)*(2*7.5)]\n",
    "\n",
    "# Define allocation budget\n",
    "allocation = 0.1/100\n",
    "\n",
    "# Plot barpolar chart\n",
    "fig, df = lca_planetary_boundaries(OUTPUT_FILE_PB, functional_unit_realizations, allocation=allocation)\n",
    "\n",
    "for idx in range(len(fig.data)):\n",
    "    fig.data[idx].theta = [s.split(\"<br>\")[1].replace(\"- \", \"<br>\") for s in fig.data[idx].theta]\n",
    "    if idx != len(fig.data)-1:\n",
    "        fig.data[idx].name = f'Scenario {idx+1} ({functional_unit_realizations[idx] / 2 :.0f} kg.km)'  # division by two: see comment above on round-trip\n",
    "        #fig.data[idx].name = f'Last mile grocery scenario ({functional_unit_realizations[idx] / 2 :.0f} kg.km/person/year)'  # division by two: see comment above on round-trip\n",
    "        fig.data[idx].marker.color=px.colors.qualitative.Plotly[idx]\n",
    "    else:\n",
    "        fig.data[idx].fillcolor='rgba(255, 0, 0, 0.3)'\n",
    "        fig.data[idx].line.color='rgba(255, 0, 0, 1.0)'\n",
    "    \n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            angle=90,\n",
    "            visible=True,\n",
    "            tickformat=\".1%\",\n",
    "            tickangle=90,\n",
    "            dtick=0.001,\n",
    "            gridcolor='lightgrey',\n",
    "            color='black',\n",
    "            linecolor='grey',\n",
    "            tickcolor='black',\n",
    "            ticks='outside'\n",
    "        ),\n",
    "        angularaxis=dict(\n",
    "            gridcolor='lightgrey',\n",
    "            showline=True,\n",
    "            linewidth=1.0,\n",
    "            linecolor='black'\n",
    "        ),\n",
    "        bgcolor='rgba(0,0,0,0)',\n",
    "    hole=0.1\n",
    "    ),\n",
    "    title=None, width=800, height=500,\n",
    "    paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)',\n",
    "    margin=dict(l=100, r=100, t=50, b=50),\n",
    "    font=dict(size=14),\n",
    "    legend=dict(yanchor=\"bottom\", xanchor=\"right\", x=.7, y=-.45, bordercolor='black', borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve data file\n",
    "OUTPUT_FILE_PB = pth.join(WORK_FOLDER_PATH, \"problem_outputs_lca_planetary_boundaries.xml\")\n",
    "\n",
    "# Define demand \n",
    "# E.g. one delivery per week of a 2 kg payload over 7.5 km (15 km round-trip), during one year = 1560 (3120 round-trip) kg.km \n",
    "# NB: check how the functional unit is defined (distance = round trip or half? For now, FAST-UAV computes LCA based on total distance so you have to multiply by 2 the delivery distance)\n",
    "#functional_unit_realizations = [(2*12)*(2*7.5), (2*52)*(2*7.5), (2*2*52)*(2*7.5)]  # [2 kg/month, 2 kg/week, 2*2kg/week] on 7.5 km (2*7.5 = 15 km round-trip)\n",
    "#functional_unit_realizations = [2*180]  # [2 kg/month] on 7.5 km (2*7.5 = 15 km round-trip)\n",
    "#functional_unit_realizations = [2*336000]  # 336 000 kg.km = last-mile delivery (< 50km) in France in 2019, per capita.\n",
    "#functional_unit_realizations = [(500+100)*(2*7.5)]  # per capita.year: 500kg food consumed + 100 kg waste (packages+food). Assumption = it is transported over 7.5km.\n",
    "#functional_unit_realizations = [(2*12)*(2*7.5), (2*52)*(2*7.5), (500+100)*(2*7.5)]  # [2 kg/week, 600kg food+waste/year] on 7.5 km (2*7.5 = 15 km round-trip)\n",
    "functional_unit_realizations = [(2*52)*(2*7.5), (500+100)*(2*7.5)]\n",
    "\n",
    "# Define allocation budget\n",
    "allocation = 0.1/100\n",
    "\n",
    "# Plot barpolar chart\n",
    "fig, df = lca_planetary_boundaries(OUTPUT_FILE_PB, functional_unit_realizations, allocation=allocation)\n",
    "\n",
    "for idx in range(len(fig.data)):\n",
    "    fig.data[idx].theta = [s.split(\"<br>\")[1].replace(\"- \", \"<br>\") for s in fig.data[idx].theta]\n",
    "    if idx != len(fig.data)-1:\n",
    "        fig.data[idx].name = f'Scenario {idx+2} ({functional_unit_realizations[idx] / 2 :.0f} kg.km)'  # division by two: see comment above on round-trip\n",
    "        #fig.data[idx].name = f'Last mile grocery scenario ({functional_unit_realizations[idx] / 2 :.0f} kg.km/person/year)'  # division by two: see comment above on round-trip\n",
    "        fig.data[idx].marker.color=px.colors.qualitative.Plotly[idx+2]\n",
    "    else:\n",
    "        fig.data[idx].fillcolor='rgba(255, 0, 0, 0.3)'\n",
    "        fig.data[idx].line.color='rgba(255, 0, 0, 1.0)'\n",
    "    \n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            type='log',\n",
    "            angle=90,\n",
    "            visible=True,\n",
    "            tickformat=\".2%\",\n",
    "            tickangle=90,\n",
    "            dtick=1,\n",
    "            range=[-5, -0.01],\n",
    "            gridcolor='lightgrey',\n",
    "            color='black',\n",
    "            linecolor='grey',\n",
    "            tickcolor='black',\n",
    "            ticks='outside'\n",
    "        ),\n",
    "        angularaxis=dict(\n",
    "            gridcolor='lightgrey',\n",
    "            showline=True,\n",
    "            linewidth=1.0,\n",
    "            linecolor='black'\n",
    "        ),\n",
    "        bgcolor='rgba(0,0,0,0)',\n",
    "    hole=0.1\n",
    "    ),\n",
    "    title=None, width=800, height=500,\n",
    "    paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)',\n",
    "    margin=dict(l=100, r=100, t=50, b=50),\n",
    "    font=dict(size=14),\n",
    "    legend=dict(yanchor=\"bottom\", xanchor=\"right\", x=.7, y=-.45, bordercolor='black', borderwidth=1),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat map of carbon budget consumption w.r.t technology assumption (emissions per kg.km) and demand (kg.km per person per year)\n",
    "\n",
    "# emissions per kg.km, in gCO2eq/kg.km\n",
    "x_vals = np.linspace(0.1, 15.0, 100)\n",
    "\n",
    "# demand in kg.km\n",
    "y_vals = np.linspace(0, 5000, 100)\n",
    "\n",
    "# share carbon budget\n",
    "z_grid = [[x_vals[i] * y_vals[j] / 985000 for i in range(len(x_vals))] for j in range(len(y_vals))] # total emissions related to carbon budget from PB (985 000 gCO2eq per capita)\n",
    "\n",
    "\n",
    "# Create the contour plot    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Contour(\n",
    "    x=x_vals, y=y_vals, z=z_grid, \n",
    "    connectgaps=True,\n",
    "    contours=dict(start=0.001, end=0.07, size=0.004, showlabels=True, labelformat=\".1%\"), \n",
    "    contours_coloring='heatmap', # can also be 'lines', or 'none'\n",
    "    colorbar=dict(\n",
    "        title='Share of safe operating space<br>for climate change', # title here\n",
    "        titleside='right',\n",
    "        titlefont=dict(size=16),\n",
    "        ticks='outside',\n",
    "        tickformat=\".0%\",\n",
    "        #dtick=0.01\n",
    "    ),\n",
    "    colorscale='RdBu_r' # Blackbody,Bluered,Blues,Cividis,Earth,Electric,Greens,Greys,Hot,Jet,Picnic,Portland,Rainbow,RdBu,Reds,Viridis,YlGnBu,YlOrRd. (add '_r' for reversed)\n",
    "))\n",
    "\n",
    "# Add point for multirotor UAV under study\n",
    "fig.add_shape(type=\"line\", \n",
    "              x0=12.9, y0=0, \n",
    "              x1=12.9, y1=5000, \n",
    "              line_width=3, line_dash=\"dot\", line_color=\"white\")\n",
    "fig.add_annotation(y=5000, x=12.9, ay=-17.0, text=\"Multirotor UAV<br>(case study)\", font=dict(color='black', ), textangle=0)\n",
    "\n",
    "# Same for lightvehicles (VUL < 2.5t)\n",
    "fig.add_shape(type=\"rect\", \n",
    "              x0=0.240, y0=0, \n",
    "              x1=1.840, y1=5000, \n",
    "              line_width=2, line_dash=\"dot\", line_color=\"white\", fillcolor=\"white\", opacity=0.5)\n",
    "fig.add_annotation(y=5000, x=1.7, ay=-17.0, text=\"Diesel Van<br>2-2.5 tons\", font=dict(color='black', ), textangle=0)\n",
    "\n",
    "# Axes titles\n",
    "fig.update_xaxes(title='Vehicle carbon intensity (gCO<sub>2eq</sub>/kg.km)', ticks='outside', dtick=1.0, titlefont=dict(size=16), showgrid=False)\n",
    "fig.update_yaxes(title='Demand (kg.km/person.year)', ticks='outside',  tickformat=\".0f\", tickvals = [0, 1000, 2000, 3000, 4000, 5000], titlefont=dict(size=16),)\n",
    "fig.update_layout(title=None, width=650, height=400, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14),\n",
    "                  margin=dict(l=0, t=0, b=0, r=0))\n",
    "\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set non-float parameters\n",
    "parameters['elec_switch_param'] = \"eu\"\n",
    "\n",
    "# Modify parameter of interest\n",
    "parameters['n_cycles'] = list(np.geomspace(1.0, 5000, 10000))\n",
    "\n",
    "# Choose lcia method\n",
    "method = [('ReCiPe 2016 v1.03, midpoint (E) no LT', 'climate change no LT', 'global warming potential (GWP1000) no LT')]\n",
    "method = [('ReCiPe 2016 v1.03, midpoint (E) no LT', 'acidification: terrestrial no LT', 'terrestrial acidification potential (TAP) no LT')]\n",
    "\n",
    "# activities and sub-activities to evaluate\n",
    "activities = [operation, production]\n",
    "\n",
    "# Have a look to NiMH batteries\n",
    "# Run LCA. The DoE is automatically performed.\n",
    "data = {'n_cycles': parameters['n_cycles']}\n",
    "parameters['battery_type'] = \"nmc_811\"\n",
    "parameters['n_cycles_battery'] = 1000\n",
    "for act in activities:\n",
    "    res = lcalg.multiLCAAlgebric(\n",
    "        act, # The model \n",
    "        method, # Impacts\n",
    "        \n",
    "        # Parameters of the model\n",
    "        **parameters\n",
    "    )\n",
    "    data[act.as_dict()['name']] = res.iloc[:, 0].values\n",
    "df1 = pd.DataFrame(data=data, index=parameters['n_cycles'])\n",
    "df1['flight hours'] = df1['n_cycles'] * parameters['mission_duration']\n",
    "df1['operation'] = 0.6 * df1['operation']\n",
    "df1['model'] = df1['operation'] + df1['production']\n",
    "df1['functional_value'] = df1['n_cycles'] * parameters['mission_duration'] * parameters['mass_payload']\n",
    "\n",
    "# Do the same with Li-ion batteries\n",
    "data = {'n_cycles': parameters['n_cycles']}\n",
    "parameters['battery_type'] = \"lfp\"\n",
    "parameters['n_cycles_battery'] = 3000\n",
    "for act in activities:\n",
    "    res = lcalg.multiLCAAlgebric(\n",
    "        act, # The model \n",
    "        method, # Impacts\n",
    "        \n",
    "        # Parameters of the model\n",
    "        **parameters\n",
    "    )\n",
    "    data[act.as_dict()['name']] = res.iloc[:, 0].values\n",
    "df2 = pd.DataFrame(data=data, index=parameters['n_cycles'])\n",
    "df2['flight hours'] = df2['n_cycles'] * parameters['mission_duration']\n",
    "df2['model'] = df2['operation'] + df2['production']\n",
    "df2['functional_value'] = df2['n_cycles'] * parameters['mission_duration'] * parameters['mass_payload']\n",
    "\n",
    "#df['model'] = df['model'] / df['functional_value']\n",
    "#df['operation'] = df['operation'] / df['functional_value']\n",
    "#df['production'] = df['production'] / df['functional_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df.plot(x='flight hours', y=['model', 'operation', 'production'], grid=True)\n",
    "\n",
    "ax = df1.plot(x='flight hours', y=['production', 'operation', 'model'])\n",
    "df2.plot(ax=ax, x='flight hours', y=['production', 'operation', 'model'], style=['--', '--', '--'], grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastoad.io import VariableIO\n",
    "from fastuav.constants import PARAM_VARIABLE_KEY\n",
    "\n",
    "# Select model\n",
    "model = get_lca_main_activity()  # top-level model\n",
    "\n",
    "# Get parameters values from problem outputs\n",
    "variables = VariableIO(DJI_M600_OUTPUT_FILE).read()\n",
    "param_names = [p for p in variables.names() if p.startswith(PARAM_VARIABLE_KEY)]\n",
    "parameters = {}\n",
    "for p in param_names:\n",
    "    parameters[p.replace(PARAM_VARIABLE_KEY, \"\")] = variables[p].value[0]\n",
    "\n",
    "# Choose method\n",
    "method = ('ReCiPe 2016 v1.03, midpoint (E) no LT', 'climate change no LT', 'global warming potential (GWP1000) no LT')\n",
    "\n",
    "# Mixed DoE + Monte Carlo\n",
    "scores = {}\n",
    "#for elec in list([\"eu\", \"us\", \"fr\"]):  # DoE\n",
    "#    parameters[\"elec_switch_param\"] = elec  # Set DoE parameter\n",
    "\n",
    "parameters[\"elec_switch_param\"] = \"fr\"\n",
    "for bat in list([\"li_ion\", \"nimh\"]):\n",
    "    parameters[\"battery_type\"] = bat\n",
    "    if bat == \"li_ion\":\n",
    "        parameters[\"n_cycles_battery\"] = 800\n",
    "    else:\n",
    "        parameters[\"n_cycles_battery\"] = 1200\n",
    "    \n",
    "    # Run Monte Carlo\n",
    "    res = LCAMonteCarlo(\n",
    "        model, # the model\n",
    "        method, # impacts to assess \n",
    "\n",
    "        # Number of Monte Carlo runs\n",
    "        n_runs=1000, \n",
    "\n",
    "        # Parameters of the model\n",
    "        **parameters\n",
    "    )\n",
    "    scores[bat] = res[0]  # score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot distributions\n",
    "for k, v in scores.items():\n",
    "    plt.hist(v, bins=50);    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST electricity mix\n",
    "\n",
    "# Import dataframes\n",
    "df1 = pd.read_csv('./workdir/df_pareto_lca_eu.csv')\n",
    "df1 = df1.sort_values(by='data:weight:mtow')\n",
    "df2 = pd.read_csv('./workdir/df_pareto_lca_fr.csv')\n",
    "df2 = df2.sort_values(by='data:weight:mtow')\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df1['data:weight:mtow'], y=df1['lca:aggregation:weighted_single_score:model_per_FU'], name=\"Europe mix\", line_shape='spline', mode='lines'),\n",
    "    secondary_y=False,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df1['data:weight:mtow'], y=df1['mission:operational:energy'], name=\"Energy consumption\", line_shape='spline', line_dash='dash', mode='lines'),\n",
    "    secondary_y=True,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df2['data:weight:mtow'], y=df2['lca:aggregation:weighted_single_score:model_per_FU'], name=\"France mix\", line_shape='spline', mode='lines'),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_vline(x=df1[df1['lca:aggregation:weighted_single_score:model_per_FU'] == df1['lca:aggregation:weighted_single_score:model_per_FU'].min()]['data:weight:mtow'].values[0], \n",
    "              line_width=1, line_dash=\"dot\", line_color=\"black\", annotation_text=\"min. mass\", annotation_position='top left', annotation_textangle=-90)\n",
    "fig.add_vline(x=df2[df2['lca:aggregation:weighted_single_score:model_per_FU'] == df2['lca:aggregation:weighted_single_score:model_per_FU'].min()]['data:weight:mtow'].values[0], \n",
    "              line_width=1, line_dash=\"dot\", line_color=\"black\", annotation_text=\"min. mass\", annotation_position='top left', annotation_textangle=-90)\n",
    "\n",
    "#fig.add_hline(y=df_energy['mission:operational:energy'].min(), line_width=1, line_dash=\"dot\", line_color=\"red\", secondary_y=True)\n",
    "#fig.add_hline(y=df_energy['lca:aggregation:weighted_single_score:model_per_FU'].min(), line_width=1, line_dash=\"dot\", line_color=\"blue\", annotation_text=\"min. impact\", annotation_position='top left', annotation_font_color='blue')\n",
    "#fig.add_annotation(x=6.25, y=df_energy['mission:operational:energy'].min(), ay=10, text=\"min. energy\", yref='y2', font=dict(color='red'))\n",
    "\n",
    "\n",
    "# Add figure title\n",
    "fig.update_layout(title=None, width=600, height=400, paper_bgcolor='rgba(0,0,0,0)',  plot_bgcolor='rgba(0,0,0,0)', font=dict(size=14), margin=dict(l=10, r=10, t=5, b=5),\n",
    "                  legend=dict(x=.5,\n",
    "                              y=.9,\n",
    "                              traceorder=\"normal\",\n",
    "                            )\n",
    "                 )\n",
    "fig.update_xaxes(title_text='UAV mass (kg)', showline=True, linewidth=1.0, linecolor='black', showgrid=False, ticks='outside')\n",
    "fig.update_yaxes(showline=True, linewidth=1, showgrid=False, ticks='outside')\n",
    "#fig.update_yaxes(range=[0.07666, 0.08658], secondary_y=False)\n",
    "#fig.update_yaxes(range=[790, 945], secondary_y=True)\n",
    "#fig.update_xaxes(range=[5.555, 6.35])\n",
    "fig.update_yaxes(title_text=\"LCA single score (points)\", secondary_y=False, \n",
    "                 titlefont=dict(color='blue'),  tickfont=dict(color='blue'), linecolor='blue',\n",
    "                )\n",
    "fig.update_yaxes(title_text=\"Mission energy consumption (kJ)\", secondary_y=True, titlefont=dict(color='red'),  tickfont=dict(color='red'), linecolor='red')\n",
    "\n",
    "fig.show()\n",
    "plotly.io.write_image(fig, 'output_file.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data, index=parameters['n_cycles_uav'])\n",
    "df['flight hours'] = df['n_cycles_uav'] * parameters['mission_duration']\n",
    "df['functional_value'] = df['n_cycles_uav'] * parameters['mission_duration'] * parameters['mass_payload']\n",
    "df.to_csv(pth.join(DATA_FOLDER_PATH, 'lca_cycles_si_nmc_fr_endpoint.csv'))\n",
    "\n",
    "#df['model per FU'] = df['model per FU'] / df['functional_value']\n",
    "#df['operation'] = df['operation'] / df['functional_value']\n",
    "#df['production'] = df['production'] / df['functional_value']\n",
    "\n",
    "ax = df.plot(x='flight hours', y=['model per FU'], grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# dict for the dataframes and their names\n",
    "dfs_NMC = {\"NMC - FR\": pd.read_csv(pth.join(DATA_FOLDER_PATH, 'lca_cycles_nmc811_fr_endpoint.csv')),\n",
    "           \"NMC - EU\": pd.read_csv(pth.join(DATA_FOLDER_PATH, 'lca_cycles_nmc811_eu_endpoint.csv')),\n",
    "           \"NMC - US\" : pd.read_csv(pth.join(DATA_FOLDER_PATH, 'lca_cycles_nmc811_us_endpoint.csv')),\n",
    "          }\n",
    "dfs_LFP = {\"LFP - FR\" : pd.read_csv(pth.join(DATA_FOLDER_PATH, 'lca_cycles_lfp_fr_endpoint.csv')),\n",
    "           \"LFP - EU\" : pd.read_csv(pth.join(DATA_FOLDER_PATH, 'lca_cycles_lfp_eu_endpoint.csv')),\n",
    "           \"LFP - US\" : pd.read_csv(pth.join(DATA_FOLDER_PATH, 'lca_cycles_lfp_us_endpoint.csv')),\n",
    "          }\n",
    "dfs_SI_NMC = {\"SI NMC - FR\" : pd.read_csv(pth.join(DATA_FOLDER_PATH, 'lca_cycles_si_nmc_fr_endpoint.csv')),\n",
    "              \"SI NMC - EU\" : pd.read_csv(pth.join(DATA_FOLDER_PATH, 'lca_cycles_si_nmc_eu_endpoint.csv')),\n",
    "              \"SI NMC - US\" : pd.read_csv(pth.join(DATA_FOLDER_PATH, 'lca_cycles_si_nmc_us_endpoint.csv')),\n",
    "          }\n",
    "\n",
    "# plot the data\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in dfs_NMC:\n",
    "    fig = fig.add_trace(go.Scatter(x = dfs_NMC[i][\"flight hours\"],\n",
    "                                   y = dfs_NMC[i][\"model per FU\"], \n",
    "                                   name = i,\n",
    "                                   line = dict(width=2)))\n",
    "for i in dfs_LFP:\n",
    "    fig = fig.add_trace(go.Scatter(x = dfs_LFP[i][\"flight hours\"],\n",
    "                                   y = dfs_LFP[i][\"model per FU\"], \n",
    "                                   name = i,\n",
    "                                   line = dict(width=2, dash='dash')))\n",
    "    \n",
    "for i in dfs_SI_NMC:\n",
    "    fig = fig.add_trace(go.Scatter(x = dfs_SI_NMC[i][\"flight hours\"],\n",
    "                                   y = dfs_SI_NMC[i][\"model per FU\"], \n",
    "                                   name = i,\n",
    "                                   line = dict(width=2, dash='dot')))\n",
    "\n",
    "fig.update_layout(title='Human Health', #Global Warming Potential',\n",
    "                   xaxis_title='Lifetime (hours)',\n",
    "                   yaxis_title='DALY', #kgCO2eq/FU',\n",
    "                  width=900,\n",
    "                  height=500,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_contour(df, x_name, y_name, z_name, levels: int = None):\n",
    "    \"\"\"\n",
    "    Contour plot from dataframe values.\n",
    "    \"\"\"\n",
    "    # Get data\n",
    "    x = df[x_name]\n",
    "    y = df[y_name]\n",
    "    z = df[z_name]\n",
    "    \n",
    "    # Initialize plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot contour\n",
    "    ax.tricontour(x, y, z, levels=levels, linewidths=0.5, colors='k')\n",
    "    cntr = ax.tricontourf(x, y, z, levels=levels, cmap=\"RdBu_r\")\n",
    "    fig.colorbar(cntr, ax=ax)\n",
    "    \n",
    "    # Data points\n",
    "    ax.plot(x, y, 'ko', ms=3)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "x_name = 'mission:operational:route_1:payload:mass'\n",
    "y_name = 'mission:operational:route_1:cruise:distance'\n",
    "z_name = 'lca:aggregation:weighted_single_score:model_per_FU'\n",
    "\n",
    "fig = plot_contour(df, x_name, y_name, z_name, levels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import os\n",
    "import os.path as pth\n",
    "from fastuav.utils.drivers.salib_doe_driver import SalibDOEDriver\n",
    "import fastoad.api as oad\n",
    "from fastoad.io.variable_io import DataFile\n",
    "import openmdao.api as om\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipywidgets import widgets, Layout\n",
    "import plotly.graph_objects as go\n",
    "from SALib.analyze import sobol, morris\n",
    "from typing import List\n",
    "from plotly.validators.scatter.marker import SymbolValidator\n",
    "import itertools\n",
    "\n",
    "SA_PATH = \"./workdir/sensitivity_analysis\"\n",
    "\n",
    "\n",
    "def doe_fast(\n",
    "    method_name: str,\n",
    "    x_dict: dict,\n",
    "    y_list: List[str],\n",
    "    conf_file: str,\n",
    "    ns: int = 100,\n",
    "    custom_driver=None,\n",
    "    calc_second_order: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    DoE function for FAST-UAV problems.\n",
    "    Various generators are available:\n",
    "        - List generator that reads cases from a provided list of DOE cases\n",
    "        - Uniform generator provided by pyDOE2 and included in OpenMDAO\n",
    "        - Latin Hypercube generator provided by OpenMDAO\n",
    "        - Generator for Sobol-Saltelli 2002 method provided by SALib\n",
    "        - Generator for Morris method provided by SALib\n",
    "    If an optimization problem is declared in the configuration file,\n",
    "    a nested optimization (sub-problem) is run (e.g. to ensure system optimality and/or consistency at each simulation).\n",
    "\n",
    "    :param method_name: 'uniform', 'lhs', 'Sobol' or 'Morris'\n",
    "    :param x_dict: inputs dictionary {input_name: [dist_parameter_1, dist_parameter_2, distribution_type]}\n",
    "    :param y_list: list of problem outputs to record\n",
    "    :param conf_file: configuration file for the problem\n",
    "    :param ns: number of samples (Uniform and Sobol) or trajectories (Morris)\n",
    "    :param calc_second_order: calculate second order indices (Sobol)\n",
    "\n",
    "    :return: dataframe of the monte carlo simulation results\n",
    "    \"\"\"\n",
    "\n",
    "    class SubProbComp(om.ExplicitComponent):\n",
    "        \"\"\"\n",
    "        Sub-problem component for nested optimization (e.g., to ensure system consistency).\n",
    "        \"\"\"\n",
    "\n",
    "        def initialize(self):\n",
    "            self.options.declare(\"conf\")\n",
    "            self.options.declare(\"x_list\")\n",
    "            self.options.declare(\"y_list\")\n",
    "\n",
    "        def setup(self):\n",
    "            # create a sub-problem to use later in the compute\n",
    "            # sub_conf = oad.FASTOADProblemConfigurator(conf_file)\n",
    "            conf = self.options[\"conf\"]\n",
    "            prob = conf.get_problem(read_inputs=True)  # get conf file (design variables, objective, driver...)\n",
    "\n",
    "            # UNCOMMENT THESE LINES IF USING CMA-ES Driver for solving sub-problem\n",
    "            # TODO: automatically detect use of CMA-ES driver\n",
    "            # driver = prob.driver = CMAESDriver()\n",
    "            # driver.CMAOptions['tolfunhist'] = 1e-4\n",
    "            # driver.CMAOptions['popsize'] = 100\n",
    "\n",
    "            # prob.driver.options['disp'] = False\n",
    "            p = self._prob = prob\n",
    "            p.setup()\n",
    "\n",
    "            # set counter for optimization failure\n",
    "            self._fail_count = 0\n",
    "\n",
    "            # define the i/o of the component\n",
    "            x_list = self._x_list = self.options[\"x_list\"]\n",
    "            y_list = self._y_list = self.options[\"y_list\"]\n",
    "\n",
    "            for x in x_list:\n",
    "                self.add_input(x)\n",
    "\n",
    "            for y in y_list:\n",
    "                self.add_output(y)\n",
    "            self.add_output('optim_failed')\n",
    "\n",
    "            self.declare_partials(\"*\", \"*\", method=\"fd\")\n",
    "\n",
    "        def compute(self, inputs, outputs):\n",
    "            p = self._prob\n",
    "            x_list = self._x_list\n",
    "            y_list = self._y_list\n",
    "\n",
    "            for x in x_list:\n",
    "                p[x] = inputs[x]\n",
    "\n",
    "            with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(\n",
    "                f\n",
    "            ):  # turn off all convergence messages (including failures)\n",
    "                fail = p.run_driver()\n",
    "\n",
    "            if fail:\n",
    "                self._fail_count += 1\n",
    "\n",
    "            for y in y_list:\n",
    "                outputs[y] = p[y]\n",
    "            outputs['optim_failed']=fail\n",
    "\n",
    "    conf = oad.FASTOADProblemConfigurator(conf_file)\n",
    "    prob_definition = conf.get_optimization_definition()\n",
    "    x_list = [x_name for x_name in x_dict.keys()]\n",
    "\n",
    "    # CASE 1: nested optimization is declared (i.e. optimization problem is defined in configuration file)\n",
    "    if \"objective\" in prob_definition.keys():\n",
    "        nested_optimization = True\n",
    "        prob = om.Problem()\n",
    "        prob.model.add_subsystem(\n",
    "            \"sub_prob\",\n",
    "            SubProbComp(\n",
    "                conf=conf,\n",
    "                x_list=x_list,\n",
    "                y_list=y_list,\n",
    "            ),\n",
    "            promotes=[\"*\"],\n",
    "        )\n",
    "\n",
    "    # CASE 2: simple model without optimization\n",
    "    else:\n",
    "        nested_optimization = False\n",
    "        prob = conf.get_problem(read_inputs=True)\n",
    "\n",
    "    # Setup driver\n",
    "    if method_name == \"list\":\n",
    "        # add input parameters for DoE\n",
    "        for x_name, x_value in x_dict.items():\n",
    "            prob.model.add_design_var(\n",
    "                x_name, lower=x_value.min(), upper=x_value.max()\n",
    "            )\n",
    "        # generate all combinations from values in the dict of parameters\n",
    "        keys, values = zip(*x_dict.items())\n",
    "        permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "        case_list = [[(key, val) for key, val in permut_dict.items()] for permut_dict in permutations_dicts]\n",
    "        prob.driver = om.DOEDriver(\n",
    "            om.ListGenerator(\n",
    "                data=case_list\n",
    "            )\n",
    "        )\n",
    "    elif method_name in (\"uniform\", \"lhs\"):\n",
    "        # add input parameters for DoE\n",
    "        for x_name, x_value in x_dict.items():\n",
    "            prob.model.add_design_var(\n",
    "                x_name, lower=x_value[0], upper=x_value[1]\n",
    "            )\n",
    "        # setup driver\n",
    "        if method_name == \"uniform\":\n",
    "            prob.driver = om.DOEDriver(\n",
    "                om.UniformGenerator(\n",
    "                    num_samples=ns\n",
    "                )\n",
    "            )\n",
    "        elif method_name == \"lhs\":\n",
    "            prob.driver = om.DOEDriver(\n",
    "                om.LatinHypercubeGenerator(\n",
    "                    samples=ns\n",
    "                )\n",
    "            )\n",
    "    elif method_name in (\"Sobol\", \"Morris\"):\n",
    "        # add input parameters for DoE\n",
    "        dists = []\n",
    "        for x_name, x_value in x_dict.items():\n",
    "            prob.model.add_design_var(\n",
    "                x_name, lower=x_value[0], upper=x_value[1]\n",
    "            )\n",
    "            dist = x_value[2]  # add distribution type ('unif' or 'norm')\n",
    "            dists.append(dist)\n",
    "        # setup driver\n",
    "        if method_name == \"Sobol\":\n",
    "            prob.driver = SalibDOEDriver(\n",
    "                sa_method_name=method_name,\n",
    "                sa_doe_options={\"n_samples\": ns, \"calc_second_order\": calc_second_order},\n",
    "                distributions=dists,\n",
    "            )\n",
    "        elif method_name == \"Morris\":\n",
    "            # setup driver\n",
    "            prob.driver = SalibDOEDriver(\n",
    "                sa_method_name=\"Morris\",\n",
    "                sa_doe_options={\"n_trajs\": ns},\n",
    "                distributions=dists,\n",
    "            )\n",
    "    elif method_name == \"custom\":\n",
    "        # add input parameters for DoE\n",
    "        for x_name, x_value in x_dict.items():\n",
    "            prob.model.add_design_var(\n",
    "                x_name, lower=x_value.min(), upper=x_value.max()\n",
    "            )\n",
    "            # setup driver\n",
    "        prob.driver=custom_driver\n",
    "\n",
    "    # Attach recorder to the driver\n",
    "    if os.path.exists(\"cases.sql\"):\n",
    "        os.remove(\"cases.sql\")\n",
    "    prob.driver.add_recorder(om.SqliteRecorder(\"cases.sql\"))\n",
    "    recorded_variables = x_list + y_list\n",
    "    if nested_optimization:\n",
    "        recorded_variables.append(\"optim_failed\")\n",
    "    prob.driver.recording_options[\"includes\"] = recorded_variables\n",
    "\n",
    "    # Run problem\n",
    "    prob.setup()\n",
    "    prob.run_driver()\n",
    "    prob.cleanup()\n",
    "\n",
    "    # Get results from recorded cases\n",
    "    df = pd.DataFrame()\n",
    "    cr = om.CaseReader(\"cases.sql\")\n",
    "    cases = cr.list_cases(\"driver\", out_stream=None)\n",
    "    for case in cases:\n",
    "        values = cr.get_case(case).outputs\n",
    "        # df = df.append(values, ignore_index=True)\n",
    "        df = pd.concat([df, pd.DataFrame(values)], ignore_index=True)\n",
    "\n",
    "    # for i in df.columns:\n",
    "    #     df[i] = df[i].apply(lambda x: x[0])\n",
    "\n",
    "    # Print number of optimization failures\n",
    "    fail_count = (\n",
    "        prob.model.sub_prob._fail_count if nested_optimization else 0\n",
    "    )  # count number of failures for nested optimization\n",
    "    if fail_count > 0:\n",
    "        print(\"%d out of %d optimizations failed.\" % (fail_count, len(cases)))\n",
    "\n",
    "    # save to .csv for future use\n",
    "    df.to_csv(SA_PATH + \"/doe_\" + method_name + \".csv\")\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
